{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1tWngIP5CvyU7H90KXCeYbnI3H7fM6e3c",
      "authorship_tag": "ABX9TyPw0muZFAELBiUMSfq7iKlq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Load Dataset üîÑ"
      ],
      "metadata": {
        "id": "lF8gLedNdQv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import csv\n",
        "from typing import List, Tuple, Any\n",
        "import math\n",
        "import pickle"
      ],
      "metadata": {
        "id": "y5hCJB4_FeVh"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "d-y8bz9OCL-A"
      },
      "outputs": [],
      "source": [
        "def load_dataset(file_path: str) -> Tuple[List[List[float]], List[Any]]:\n",
        "    \"\"\"\n",
        "    Loads the dataset from a CSV file.\n",
        "\n",
        "    This function assumes that the CSV file has a header row and that:\n",
        "    - All columns except the last one are features (converted to float).\n",
        "    - The last column is the label (left as a string; convert if needed).\n",
        "\n",
        "    Note:\n",
        "      The current implementation is particularly suited for datasets like the Iris dataset.\n",
        "      For other datasets, you might want to modify the logic (e.g., to change the label column index).\n",
        "\n",
        "    Parameters:\n",
        "      file_path (str): Path to the dataset file.\n",
        "\n",
        "    Returns:\n",
        "      Tuple[List[List[float]], List[Any]]:\n",
        "          - data: A list of rows, each row is a list of features as floats.\n",
        "          - labels: A list of labels corresponding to each row.\n",
        "    \"\"\"\n",
        "    data: List[List[float]] = []\n",
        "    labels: List[Any] = []\n",
        "\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            reader = csv.reader(file)\n",
        "            header = next(reader, None)  # Skip header row if exists\n",
        "\n",
        "            # Process each row in the CSV file\n",
        "            for row in reader:\n",
        "                if row:  # Ensure the row is not empty\n",
        "                    # Convert all columns except the last one into floats (features)\n",
        "                    try:\n",
        "                        features = [float(item) for item in row[:-1]]\n",
        "                    except ValueError as ve:\n",
        "                        print(f\"Could not convert features to float in row: {row}. Error: {ve}\")\n",
        "                        continue\n",
        "                    # The last column is considered the label (remains as string or processed further)\n",
        "                    label = row[-1]\n",
        "\n",
        "                    data.append(features)\n",
        "                    labels.append(label)\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File not found: {file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading the file: {e}\")\n",
        "\n",
        "    return data, labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    dataset, labels = load_dataset('/content/drive/MyDrive/Colab Notebooks/Iris Classification/Iris.csv')\n",
        "    print(dataset[:3],\"\\n\")\n",
        "    print(labels[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5moBn_B-ewV",
        "outputId": "5b5a352a-aaad-4922-aba2-422c17fd8036"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0, 5.1, 3.5, 1.4, 0.2], [2.0, 4.9, 3.0, 1.4, 0.2], [3.0, 4.7, 3.2, 1.3, 0.2]] \n",
            "\n",
            "['Iris-setosa', 'Iris-setosa', 'Iris-setosa']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_dataset(dataset: List[List[Any]]) -> bool:\n",
        "    \"\"\"\n",
        "    ÿ®ÿ±ÿ±ÿ≥€å ÿµÿ≠ÿ™ ÿ≥ÿßÿÆÿ™ÿßÿ± Ÿà €å⁄©Ÿæÿßÿ±⁄Ü⁄Ø€å ŸÖÿ¨ŸÖŸàÿπŸá ÿØÿßÿØŸá.\n",
        "\n",
        "    ÿß€åŸÜ ÿ™ÿßÿ®ÿπ ÿ®ÿ±ÿ±ÿ≥€å ŸÖ€å‚Äå⁄©ŸÜÿØ ⁄©Ÿá:\n",
        "      - ŸÖÿ¨ŸÖŸàÿπŸá ÿØÿßÿØŸá ÿÆÿßŸÑ€å ŸÜÿ®ÿßÿ¥ÿØ.\n",
        "      - ÿ™ŸÖÿßŸÖ€å ÿ±ÿØ€åŸÅ‚ÄåŸáÿß€å ŸÖÿ¨ŸÖŸàÿπŸá ÿØÿßÿØŸá ÿØÿßÿ±ÿß€å ÿ™ÿπÿØÿßÿØ Ÿà€å⁄ò⁄Ø€å €å⁄©ÿ≥ÿßŸÜ ÿ®ÿßÿ¥ŸÜÿØ.\n",
        "\n",
        "    Ÿæÿßÿ±ÿßŸÖÿ™ÿ±Ÿáÿß:\n",
        "      dataset (List[List[Any]]): ŸÑ€åÿ≥ÿ™€å ÿßÿ≤ ÿ±ÿØ€åŸÅ‚ÄåŸáÿß€å ÿØÿßÿØŸáÿõ Ÿáÿ± ÿ±ÿØ€åŸÅ ŸÜ€åÿ≤ ŸÑ€åÿ≥ÿ™€å ÿßÿ≤ Ÿà€å⁄ò⁄Ø€å‚ÄåŸáÿßÿ≥ÿ™.\n",
        "\n",
        "    ÿÆÿ±Ÿàÿ¨€å:\n",
        "      bool: ÿß⁄Øÿ± ŸÖÿ¨ŸÖŸàÿπŸá ÿØÿßÿØŸá ÿµÿ≠€åÿ≠ ÿ®ÿßÿ¥ÿØÿå ŸÖŸÇÿØÿßÿ± True Ÿà ÿØÿ± ÿ∫€åÿ± ÿß€åŸÜ ÿµŸàÿ±ÿ™ False ÿ®ÿ±ŸÖ€å‚Äå⁄Øÿ±ÿØÿßŸÜÿØ.\n",
        "    \"\"\"\n",
        "    # ÿß⁄Øÿ± ŸÖÿ¨ŸÖŸàÿπŸá ÿØÿßÿØŸá ÿÆÿßŸÑ€å ÿ®ÿßÿ¥ÿØÿå ŸÖÿπÿ™ÿ®ÿ± ŸÜ€åÿ≥ÿ™.\n",
        "    if not dataset:\n",
        "        return False\n",
        "\n",
        "    # ÿ™ÿπÿØÿßÿØ Ÿà€å⁄ò⁄Ø€å‚ÄåŸáÿß ÿØÿ± ÿßŸàŸÑ€åŸÜ ÿ±ÿØ€åŸÅ ÿ±ÿß ÿ®Ÿá ÿπŸÜŸàÿßŸÜ ŸÖÿ®ŸÜÿß ÿØÿ± ŸÜÿ∏ÿ± ŸÖ€å‚Äå⁄Ø€åÿ±€åŸÖ.\n",
        "    num_features = len(dataset[0])\n",
        "    for row in dataset:\n",
        "        # ÿ®ÿ±ÿ±ÿ≥€å ŸÖ€å‚Äå⁄©ŸÜÿØ ⁄©Ÿá Ÿáÿ± ÿ±ÿØ€åŸÅ ŸáŸÖÿßŸÜ ÿ™ÿπÿØÿßÿØ Ÿà€å⁄ò⁄Ø€å ÿ®ÿß ÿ±ÿØ€åŸÅ ÿßŸàŸÑ€åŸá ÿØÿßÿ¥ÿ™Ÿá ÿ®ÿßÿ¥ÿØ.\n",
        "        if len(row) != num_features:\n",
        "            return False\n",
        "    return True"
      ],
      "metadata": {
        "id": "br0ElRjWdxiw"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # ŸÜŸÖŸàŸÜŸá‚Äåÿß€å ÿßÿ≤ €å⁄© ŸÖÿ¨ŸÖŸàÿπŸá ÿØÿßÿØŸá ŸÖÿπÿ™ÿ®ÿ± (ŸÖÿ´ŸÑÿßŸã ÿ®ÿ±ÿß€å ÿØ€åÿ™ÿßÿ≥ÿ™ Iris €åÿß ÿ≥ÿß€åÿ± ÿØ€åÿ™ÿßÿ≥ÿ™‚ÄåŸáÿß)\n",
        "    valid_dataset = [\n",
        "        [5.1, 3.5, 1.4, 0.2],\n",
        "        [4.9, 3.0, 1.4, 0.2],\n",
        "        [6.2, 3.4, 5.4, 2.3]\n",
        "    ]\n",
        "\n",
        "    # ŸÜŸÖŸàŸÜŸá‚Äåÿß€å ÿßÿ≤ €å⁄© ŸÖÿ¨ŸÖŸàÿπŸá ÿØÿßÿØŸá ŸÜÿßŸÖÿπÿ™ÿ®ÿ± (€å⁄© ÿ±ÿØ€åŸÅ ÿ®ÿß ÿ™ÿπÿØÿßÿØ Ÿà€å⁄ò⁄Ø€å ŸÖÿ™ŸÅÿßŸàÿ™)\n",
        "    invalid_dataset = [\n",
        "        [5.1, 3.5, 1.4, 0.2],\n",
        "        [4.9, 3.0, 1.4],  # ÿß€åŸÜ ÿ±ÿØ€åŸÅ ÿ™ÿπÿØÿßÿØ Ÿà€å⁄ò⁄Ø€å ⁄©ŸÖÿ™ÿ±€å ŸÜÿ≥ÿ®ÿ™ ÿ®Ÿá ÿ®ŸÇ€åŸá ÿØÿßÿ±ÿØ.\n",
        "        [6.2, 3.4, 5.4, 2.3]\n",
        "    ]\n",
        "\n",
        "    # ÿßÿ¨ÿ±ÿß€å ÿ™ÿßÿ®ÿπ Ÿà ⁄ÜÿßŸæ ŸÜÿ™ÿß€åÿ¨\n",
        "    print(\"ŸÖÿ¨ŸÖŸàÿπŸá ÿØÿßÿØŸá ŸÖÿπÿ™ÿ®ÿ±:\", validate_dataset(valid_dataset))    # ÿÆÿ±Ÿàÿ¨€å: True\n",
        "    print(\"ŸÖÿ¨ŸÖŸàÿπŸá ÿØÿßÿØŸá ŸÜÿßŸÖÿπÿ™ÿ®ÿ±:\", validate_dataset(invalid_dataset))  # ÿÆÿ±Ÿàÿ¨€å: False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuwqFF-WEiB9",
        "outputId": "248702ae-e8ed-4a7e-84e9-81713273cd25"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ŸÖÿ¨ŸÖŸàÿπŸá ÿØÿßÿØŸá ŸÖÿπÿ™ÿ®ÿ±: True\n",
            "ŸÖÿ¨ŸÖŸàÿπŸá ÿØÿßÿØŸá ŸÜÿßŸÖÿπÿ™ÿ®ÿ±: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_data_loading(file_path: str) -> None:\n",
        "    \"\"\"\n",
        "    ÿ¢ÿ≤ŸÖŸàŸÜ ÿπŸÖŸÑ⁄©ÿ±ÿØ ÿ™ÿßÿ®ÿπ ÿ®ÿßÿ±⁄Øÿ∞ÿßÿ±€å ÿØÿßÿØŸá.\n",
        "\n",
        "    Ÿàÿ±ŸàÿØ€å:\n",
        "      file_path (str): ŸÖÿ≥€åÿ± ŸÅÿß€åŸÑ CSV ÿ®ÿ±ÿß€å ÿ®ÿßÿ±⁄Øÿ∞ÿßÿ±€å ÿØÿßÿØŸá‚ÄåŸáÿß.\n",
        "\n",
        "    ÿÆÿ±Ÿàÿ¨€å:\n",
        "      None: ŸÜÿ™€åÿ¨Ÿá ÿ™ÿ≥ÿ™ ÿßÿ≤ ÿ∑ÿ±€åŸÇ ⁄ÜÿßŸæ Ÿæ€åÿßŸÖ ÿ®Ÿá ⁄©ŸÜÿ≥ŸàŸÑ ŸÜŸÖÿß€åÿ¥ ÿØÿßÿØŸá ŸÖ€å‚Äåÿ¥ŸàÿØ.\n",
        "\n",
        "    ÿ™Ÿàÿ∂€åÿ≠ÿßÿ™:\n",
        "      ÿß€åŸÜ ÿ™ÿßÿ®ÿπ ÿßÿ®ÿ™ÿØÿß ÿØÿßÿØŸá‚ÄåŸáÿß Ÿà ÿ®ÿ±⁄Üÿ≥ÿ®‚ÄåŸáÿß ÿ±ÿß ÿßÿ≤ ŸÅÿß€åŸÑ Ÿàÿ±ŸàÿØ€å ÿ®ÿß ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ load_dataset ŸÖ€å‚ÄåÿÆŸàÿßŸÜÿØ.\n",
        "      ÿ≥Ÿæÿ≥ ÿ®ÿß ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ validate_dataset ÿßÿπÿ™ÿ®ÿßÿ± ÿØÿßÿØŸá‚ÄåŸáÿß ÿ±ÿß ÿ®ÿ±ÿ±ÿ≥€å ŸÖ€å‚Äå⁄©ŸÜÿØ.\n",
        "      ÿØÿ± ÿµŸàÿ±ÿ™ ŸÖŸàŸÅŸÇ€åÿ™ÿå Ÿæ€åÿßŸÖ ŸÖŸàŸÅŸÇ€åÿ™ ÿ±ÿß ⁄ÜÿßŸæ ŸÖ€å‚Äå⁄©ŸÜÿØ Ÿà ÿØÿ± ÿµŸàÿ±ÿ™ ÿ®ÿ±Ÿàÿ≤ ÿÆÿ∑ÿßÿå Ÿæ€åÿ∫ÿßŸÖ ŸÖŸÜÿßÿ≥ÿ® ÿ±ÿß ⁄ÜÿßŸæ ŸÖ€å‚Äå⁄©ŸÜÿØ.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        dataset, labels = load_dataset(file_path)\n",
        "        assert validate_dataset(dataset), \"Dataset validation failed.\"\n",
        "        print(\"Data loaded and validated successfully.\")\n",
        "    except AssertionError as error:\n",
        "        print(f\"Test failed: {error}\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"File not found. Make sure the dataset file exists at the specified path.\")\n",
        "    except Exception as error:\n",
        "        print(f\"An error occurred: {error}\")"
      ],
      "metadata": {
        "id": "mKGpyOkmd8ke"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_loading('/content/drive/MyDrive/Colab Notebooks/Iris Classification/Iris.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "085zceueHOJl",
        "outputId": "28327a88-8b43-4f80-901e-c478870e1d8a"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded and validated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Normalize the Data üîÑ"
      ],
      "metadata": {
        "id": "PBavN6UwmFU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transpose(data: List[List]) -> List[List]:\n",
        "    \"\"\"\n",
        "    ÿ™ÿ±ÿßŸÜŸáÿßÿØŸá ⁄©ÿ±ÿØŸÜ €å⁄© ŸÑ€åÿ≥ÿ™ ÿØŸàÿ®ÿπÿØ€å.\n",
        "\n",
        "    Ÿæÿßÿ±ÿßŸÖÿ™ÿ±Ÿáÿß:\n",
        "        data (List[List]): ÿØÿßÿØŸá‚ÄåŸáÿß ÿ®Ÿá‚ÄåÿµŸàÿ±ÿ™ ŸÑ€åÿ≥ÿ™ ÿßÿ≤ ŸÑ€åÿ≥ÿ™‚ÄåŸáÿß (ŸÖÿ´ŸÑÿßŸã ŸÖÿßÿ™ÿ±€åÿ≥)\n",
        "\n",
        "    ÿÆÿ±Ÿàÿ¨€å:\n",
        "        List[List]: ÿØÿßÿØŸá‚ÄåŸáÿß€å ÿ™ÿ±ÿßŸÜŸáÿßÿØŸá‚Äåÿ¥ÿØŸá\n",
        "    \"\"\"\n",
        "    # ÿπŸÑÿßŸÖÿ™ ÿ≥ÿ™ÿßÿ±Ÿá ÿØÿßÿØŸá Ÿáÿß ÿ±ÿß ÿ¢ŸÜŸæ⁄© ŸÖ€å⁄©ŸÜÿØ\n",
        "    # ÿ™ÿßÿ®ÿπ ÿ≤€åŸæ ÿ≥ÿ™ŸàŸÜ n ÿßÿ≤ Ÿáÿ± ÿ≥ÿ∑ÿ± ÿ±ÿß ⁄©ŸÜÿßÿ± ŸáŸÖ ŸÇÿ±ÿßÿ± ŸÖ€åÿØŸáÿØ Ÿà ÿ®ÿØ€åŸÜ Ÿàÿ≥€åŸÑŸá ÿØÿßÿØŸá Ÿáÿß ÿ±ÿß ÿ™ÿ±ÿßŸÜÿ≥ŸæŸàÿ≤Ÿá ŸÖ€å⁄©ŸÜÿØ.\n",
        "    return [list(row) for row in zip(*data)]"
      ],
      "metadata": {
        "id": "ILbm5BhKp2fJ"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def min_max_normalizer(data: List[List[float]]) -> List[List[float]]:\n",
        "    \"\"\"\n",
        "    ÿß€åŸÜ ÿ™ÿßÿ®ÿπ ÿØÿßÿØŸá‚ÄåŸáÿß€å ÿπÿØÿØ€å ÿ±Ÿà ÿ®ÿß ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ÿ±Ÿàÿ¥ Min-Max ŸÜÿ±ŸÖÿßŸÑ ŸÖ€å‚Äå⁄©ŸÜŸá.\n",
        "    €åÿπŸÜ€å ŸáŸÖŸá‚Äå€å ÿßÿπÿØÿßÿØ ÿ±Ÿà ÿ®€åŸÜ 0 Ÿà 1 ŸÖ€åÿßÿ±Ÿáÿå ÿ™ÿß ŸÖŸÇÿß€åÿ≥Ÿá Ÿà ÿ¢ŸÖŸàÿ≤ÿ¥ ŸÖÿØŸÑ ÿ≥ÿßÿØŸá‚Äåÿ™ÿ± ÿ®ÿ¥Ÿá.\n",
        "    \"\"\"\n",
        "\n",
        "    # ⁄Üÿ±ÿÆŸàŸÜÿØŸÜ ŸÖÿßÿ™ÿ±€åÿ≥ ÿ®ÿ±ÿß€å ÿ®ÿ±ÿ±ÿ≥€å Ÿáÿ± Ÿà€å⁄ò⁄Ø€å ÿ®Ÿá‚ÄåÿµŸàÿ±ÿ™ ÿ≥ÿ™ŸàŸÜ€å\n",
        "    transposed_data = transpose(data)\n",
        "\n",
        "    # Ÿæ€åÿØÿß ⁄©ÿ±ÿØŸÜ ŸÖ€åŸÜ€åŸÖŸÖ Ÿà ŸÖÿß⁄©ÿ≤€åŸÖŸÖ Ÿáÿ± ÿ≥ÿ™ŸàŸÜ\n",
        "    min_vals = [min(col) for col in transposed_data]\n",
        "    max_vals = [max(col) for col in transposed_data]\n",
        "\n",
        "    scaled_data = []\n",
        "\n",
        "    # ŸÜÿ±ŸÖÿßŸÑ ⁄©ÿ±ÿØŸÜ Ÿáÿ± ŸÖŸÇÿØÿßÿ± ÿ®ÿß ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ŸÅÿ±ŸÖŸàŸÑ min-max\n",
        "    for row_index, row in enumerate(data):\n",
        "        scaled_row = []\n",
        "        for val, min_val, max_val in zip(row, min_vals, max_vals):\n",
        "            range_val = max_val - min_val\n",
        "            if range_val == 0:\n",
        "                scaled_row.append(0.0)  # ÿß⁄Øÿ± ŸáŸÖŸá ŸÖŸÇÿßÿØ€åÿ± ÿ®ÿ±ÿßÿ®ÿ± ÿ®ŸàÿØŸÜÿå ÿÆÿ±Ÿàÿ¨€å ÿ±Ÿà ÿµŸÅÿ± ÿ®ÿ≤ÿßÿ±\n",
        "            else:\n",
        "                scaled_val = (val - min_val) / range_val\n",
        "                scaled_row.append(scaled_val)\n",
        "        scaled_data.append(scaled_row)\n",
        "\n",
        "    return scaled_data"
      ],
      "metadata": {
        "id": "GHEPq3Qnm84C"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(dataset: List[List[float]], training_size: float = 0.7, validation_size: float = 0.0) -> Tuple[List[List[float]], List[List[float]], List[List[float]]]:\n",
        "    \"\"\"\n",
        "    ÿß€åŸÜ ÿ™ÿßÿ®ÿπ ÿØ€åÿ™ÿßÿ≥ÿ™ ÿ±Ÿà ÿ®Ÿá ÿ≥Ÿá ÿ®ÿÆÿ¥ ÿ™ŸÇÿ≥€åŸÖ ŸÖ€å‚Äå⁄©ŸÜŸá: ÿ¢ŸÖŸàÿ≤ÿ¥ÿå ÿßÿπÿ™ÿ®ÿßÿ±ÿ≥ŸÜÿ¨€å Ÿà ÿ™ÿ≥ÿ™.\n",
        "\n",
        "    Ÿæÿßÿ±ÿßŸÖÿ™ÿ±Ÿáÿß:\n",
        "    dataset (list of lists): ÿØ€åÿ™ÿß€å Ÿàÿ±ŸàÿØ€å ⁄©Ÿá ŸÖ€å‚ÄåÿÆŸàÿß€åŸÖ ÿ™ŸÇÿ≥€åŸÖÿ¥ ⁄©ŸÜ€åŸÖ.\n",
        "    training_size (float): ÿØÿ±ÿµÿØ€å ÿßÿ≤ ÿØ€åÿ™ÿß ⁄©Ÿá ÿ®ÿ±ÿß€å ÿ¢ŸÖŸàÿ≤ÿ¥ ÿßÿ≥ÿ™ŸÅÿßÿØŸá ŸÖ€åÿ¥Ÿá (ŸÖÿ´ŸÑÿßŸã €∞.€∑ €åÿπŸÜ€å €∑€∞Ÿ™).\n",
        "    validation_size (float): ÿØÿ±ÿµÿØ€å ÿßÿ≤ ÿØ€åÿ™ÿß ⁄©Ÿá ÿ®ÿ±ÿß€å ÿßÿπÿ™ÿ®ÿßÿ±ÿ≥ŸÜÿ¨€å ÿßÿ≥ÿ™ŸÅÿßÿØŸá ŸÖ€åÿ¥Ÿá (ŸÖÿ´ŸÑÿßŸã €∞.€±€µ €åÿπŸÜ€å €±€µŸ™).\n",
        "\n",
        "    ÿÆÿ±Ÿàÿ¨€å:\n",
        "    €åŸá ÿ™ÿßŸæŸÑ ÿ¥ÿßŸÖŸÑ ÿ≥Ÿá ÿ™ÿß ŸÑ€åÿ≥ÿ™Ÿá: ÿØ€åÿ™ÿß€å ÿ¢ŸÖŸàÿ≤ÿ¥ÿå ÿØ€åÿ™ÿß€å ÿßÿπÿ™ÿ®ÿßÿ±ÿ≥ŸÜÿ¨€åÿå ÿØ€åÿ™ÿß€å ÿ™ÿ≥ÿ™.\n",
        "    \"\"\"\n",
        "\n",
        "    # ÿßŸàŸÑ ÿØ€åÿ™ÿß ÿ±Ÿà ÿ®Ÿá ÿµŸàÿ±ÿ™ ÿ™ÿµÿßÿØŸÅ€å ŸÇÿßÿ∑€å ŸÖ€å‚Äå⁄©ŸÜ€åŸÖ ⁄©Ÿá ÿ™ÿ±ÿ™€åÿ®ÿ¥ ÿ™ÿ£ÿ´€åÿ± ŸÜÿ∞ÿßÿ±Ÿá\n",
        "    random.shuffle(dataset)\n",
        "\n",
        "    # ÿßŸÜÿØÿßÿ≤Ÿá ⁄©ŸÑ ÿØ€åÿ™ÿß\n",
        "    total_size = len(dataset)\n",
        "\n",
        "    # ŸÖÿ≠ÿßÿ≥ÿ®Ÿá ŸÖÿ±ÿ≤ ÿ®€åŸÜ ÿ®ÿÆÿ¥‚ÄåŸáÿß\n",
        "    train_end = int(training_size * total_size)\n",
        "    val_end = int((training_size) * total_size)\n",
        "\n",
        "    # ÿ®ÿ±ÿ¥ ÿØÿßÿØŸÜ ÿØ€åÿ™ÿß ÿ®ÿ± ÿßÿ≥ÿßÿ≥ ÿØÿ±ÿµÿØŸáÿß\n",
        "    training_data = dataset[:train_end]\n",
        "    # validation_data = dataset[train_end:val_end]\n",
        "    validation_data = [[]]\n",
        "    test_data = dataset[val_end:]\n",
        "\n",
        "    return training_data, validation_data, test_data\n"
      ],
      "metadata": {
        "id": "JUk8uAB0k1F1"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    [5.1, 3.5, 1.4, 0.2],\n",
        "    [4.9, 3.0, 1.4, 0.2],\n",
        "    [6.2, 3.4, 5.4, 2.3],\n",
        "    [5.9, 3.0, 5.1, 1.8],\n",
        "    [5.4, 3.9, 1.7, 0.4],\n",
        "    [6.7, 3.1, 4.7, 1.5],\n",
        "    [5.6, 2.8, 4.9, 2.0],\n",
        "    [5.7, 2.1, 4.0, 2.1],\n",
        "    [5.8, 2.2, 9.4, 1.2],\n",
        "    [5.9, 2.3, 5.5, 0.8],\n",
        "]\n",
        "\n",
        "train, val, test = split_data(data, training_size=0.5, validation_size=0.2)\n",
        "print(\"Train:\", train)\n",
        "print(\"Validation:\", val)\n",
        "print(\"Test:\", test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vsrx7eIk6nIH",
        "outputId": "98e312bb-03ad-4fd3-dc42-c3e4622e579d"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: [[6.2, 3.4, 5.4, 2.3], [5.9, 2.3, 5.5, 0.8], [5.6, 2.8, 4.9, 2.0], [5.9, 3.0, 5.1, 1.8], [5.4, 3.9, 1.7, 0.4]]\n",
            "Validation: [[5.7, 2.1, 4.0, 2.1], [5.1, 3.5, 1.4, 0.2]]\n",
            "Test: [[6.7, 3.1, 4.7, 1.5], [5.8, 2.2, 9.4, 1.2], [4.9, 3.0, 1.4, 0.2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_split_data():\n",
        "    \"\"\"\n",
        "    ÿß€åŸÜ ÿ™ÿßÿ®ÿπ ÿ®ÿ±ÿ±ÿ≥€å ŸÖ€å‚Äå⁄©ŸÜŸá ⁄©Ÿá ÿ™ÿßÿ®ÿπ split_data ÿØÿ±ÿ≥ÿ™ ⁄©ÿßÿ± ŸÖ€å‚Äå⁄©ŸÜŸá €åÿß ŸÜŸá.\n",
        "    ÿ™Ÿà€å ÿ™ÿ≥ÿ™ÿå ÿßŸàŸÑ ÿØ€åÿ™ÿßÿ≥ÿ™ ÿ±Ÿà ŸÑŸàÿØ ŸÖ€å‚Äå⁄©ŸÜ€åŸÖÿå ÿ®ÿπÿØ ŸÜÿ±ŸÖÿßŸÑÿß€åÿ≤ÿ¥ ŸÖ€å‚Äå⁄©ŸÜ€åŸÖÿå ÿ®ÿπÿØ ÿ™ŸÇÿ≥€åŸÖÿ¥ ŸÖ€å‚Äå⁄©ŸÜ€åŸÖ.\n",
        "    ÿ®ÿπÿØÿ¥ ⁄Ü⁄© ŸÖ€å‚Äå⁄©ŸÜ€åŸÖ ⁄©Ÿá Ÿáÿ± ÿ®ÿÆÿ¥ ÿßÿ≤ ÿØ€åÿ™ÿß ÿÆÿßŸÑ€å ŸÜÿ®ÿßÿ¥Ÿá Ÿà ŸÖÿ¨ŸÖŸàÿπÿ¥ŸàŸÜ ŸáŸÖ ÿ®ÿ±ÿßÿ®ÿ± ÿ®ÿß ÿØ€åÿ™ÿß€å ÿßŸàŸÑ€åŸá ÿ®ÿßÿ¥Ÿá.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # ŸÖÿ≥€åÿ± ŸÅÿß€åŸÑ ÿØ€åÿ™ÿßÿ≥ÿ™\n",
        "        file_path = '/content/drive/MyDrive/Colab Notebooks/Iris Classification/Iris.csv'\n",
        "\n",
        "        # ŸÑŸàÿØ ⁄©ÿ±ÿØŸÜ ÿØ€åÿ™ÿß Ÿà ŸÑ€åÿ®ŸÑ‚ÄåŸáÿß\n",
        "        dataset, labels = load_dataset(file_path)\n",
        "\n",
        "        # ŸÜÿ±ŸÖÿßŸÑ‚Äåÿ≥ÿßÿ≤€å ÿØ€åÿ™ÿß ÿ®ÿß Min-Max\n",
        "        dataset = min_max_normalizer(dataset)\n",
        "\n",
        "        # ÿ™ŸÇÿ≥€åŸÖ ÿØ€åÿ™ÿß ÿ®Ÿá ÿ≥Ÿá ÿ®ÿÆÿ¥\n",
        "        training_data, validation_data, test_data = split_data(dataset)\n",
        "\n",
        "        # ÿ™ÿ≥ÿ™ ÿß€åŸÜ⁄©Ÿá Ÿá€å⁄Ü‚Äå⁄©ÿØŸàŸÖ ÿßÿ≤ ÿ®ÿÆÿ¥‚ÄåŸáÿß ÿÆÿßŸÑ€å ŸÜÿ®ÿßÿ¥Ÿá\n",
        "        assert len(training_data) > 0, \"ÿØÿßÿØŸá‚ÄåŸáÿß€å ÿ¢ŸÖŸàÿ≤ÿ¥ ÿÆÿßŸÑ€åŸá.\"\n",
        "        assert len(validation_data) > 0, \"ÿØÿßÿØŸá‚ÄåŸáÿß€å ÿßÿπÿ™ÿ®ÿßÿ±ÿ≥ŸÜÿ¨€å ÿÆÿßŸÑ€åŸá.\"\n",
        "        assert len(test_data) > 0, \"ÿØÿßÿØŸá‚ÄåŸáÿß€å ÿ™ÿ≥ÿ™ ÿÆÿßŸÑ€åŸá.\"\n",
        "\n",
        "        # ÿ™ÿ≥ÿ™ ÿß€åŸÜ⁄©Ÿá ÿ™ÿπÿØÿßÿØ ⁄©ŸÑ ÿØÿßÿØŸá‚ÄåŸáÿß ÿ™ÿ∫€å€åÿ± ŸÜ⁄©ÿ±ÿØŸá ÿ®ÿßÿ¥Ÿá\n",
        "        total_size = len(training_data) + len(validation_data) + len(test_data)\n",
        "        assert total_size == len(dataset), \"ÿÆÿ∑ÿß ÿØÿ± ÿ™ŸÇÿ≥€åŸÖ ÿØ€åÿ™ÿß: ÿ™ÿπÿØÿßÿØ ŸÜŸáÿß€å€å ÿ®ÿß ÿßŸàŸÑ€åŸá ŸÜŸÖ€å‚ÄåÿÆŸàŸÜŸá.\"\n",
        "\n",
        "        print(\"‚úÖ ÿ™ÿ≥ÿ™ ÿ™ŸÇÿ≥€åŸÖ ÿØ€åÿ™ÿß ÿ®ÿß ŸÖŸàŸÅŸÇ€åÿ™ ÿßŸÜÿ¨ÿßŸÖ ÿ¥ÿØ.\")\n",
        "\n",
        "    except AssertionError as error:\n",
        "        print(f\"‚ùå ÿ™ÿ≥ÿ™ ÿ¥⁄©ÿ≥ÿ™ ÿÆŸàÿ±ÿØ: {error}\")\n",
        "\n",
        "    except Exception as error:\n",
        "        print(f\"‚ö†Ô∏è €åŸá ÿÆÿ∑ÿß€å€å Ÿæ€åÿ¥ ÿßŸàŸÖÿØ: {error}\")\n"
      ],
      "metadata": {
        "id": "EH-SJwTEk4PT"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_split_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tH4BxNlN7rjY",
        "outputId": "e57979c5-290d-4e94-a297-12ca482197ec"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ÿ™ÿ≥ÿ™ ÿ™ŸÇÿ≥€åŸÖ ÿØ€åÿ™ÿß ÿ®ÿß ŸÖŸàŸÅŸÇ€åÿ™ ÿßŸÜÿ¨ÿßŸÖ ÿ¥ÿØ.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Define the Architecture üèó"
      ],
      "metadata": {
        "id": "VUV-OoGf9CoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Neuron:\n",
        "    \"\"\"⁄©ŸÑÿßÿ≥ €å⁄© ŸÜŸàÿ±ŸàŸÜ ÿ≥ÿßÿØŸá ⁄©Ÿá ÿ®ÿ±ÿß€å ŸÖÿ≠ÿßÿ≥ÿ®Ÿá ÿÆÿ±Ÿàÿ¨€åÿå ⁄Øÿ±ÿßÿØ€åÿßŸÜ Ÿà ÿ®Ÿá‚Äåÿ±Ÿàÿ≤ÿ±ÿ≥ÿßŸÜ€å Ÿàÿ≤ŸÜ‚ÄåŸáÿß ÿßÿ≥ÿ™ŸÅÿßÿØŸá ŸÖ€å‚Äåÿ¥ŸàÿØ.\"\"\"\n",
        "\n",
        "    def __init__(self, weights: List[float], bias: float = None):\n",
        "        \"\"\"\n",
        "        ŸÜŸàÿ±ŸàŸÜ ÿ®ÿß Ÿàÿ≤ŸÜ‚ÄåŸáÿß Ÿà ÿ®ÿß€åÿßÿ≥ ÿØÿßÿØŸá‚Äåÿ¥ÿØŸá ŸÖŸÇÿØÿßÿ±ÿØŸá€å ÿßŸàŸÑ€åŸá ŸÖ€å‚Äåÿ¥ŸàÿØ.\n",
        "\n",
        "        ÿ¢ÿ±⁄ØŸàŸÖÿßŸÜ‚ÄåŸáÿß:\n",
        "        weights: ŸÑ€åÿ≥ÿ™€å ÿßÿ≤ Ÿàÿ≤ŸÜ‚ÄåŸáÿß ÿ®ÿ±ÿß€å Ÿàÿ±ŸàÿØ€å‚ÄåŸáÿß€å ŸÜŸàÿ±ŸàŸÜ.\n",
        "        bias: ŸÖŸÇÿØÿßÿ± ÿ®ÿß€åÿßÿ≥ ÿ®ÿ±ÿß€å ŸÜŸàÿ±ŸàŸÜ. ÿß⁄Øÿ± ÿØÿßÿØŸá ŸÜÿ¥ŸàÿØÿå €å⁄© ŸÖŸÇÿØÿßÿ± ÿ™ÿµÿßÿØŸÅ€å ÿ®€åŸÜ -0.1 Ÿà 0.1 ÿ®Ÿá ÿ¢ŸÜ ÿßÿÆÿ™ÿµÿßÿµ ŸÖ€å‚Äå€åÿßÿ®ÿØ.\n",
        "        \"\"\"\n",
        "        self.weights = weights\n",
        "        self.bias = bias if bias is not None else random.uniform(-0.1, 0.1)\n",
        "        self.inputs = []  # Ÿàÿ±ŸàÿØ€å‚ÄåŸáÿß€å ŸÜŸàÿ±ŸàŸÜ ÿ±ÿß ÿ∞ÿÆ€åÿ±Ÿá ŸÖ€å‚Äå⁄©ŸÜÿØ\n",
        "        self.output = 0   # ÿÆÿ±Ÿàÿ¨€å ŸÜŸàÿ±ŸàŸÜ ÿ±ÿß ÿ∞ÿÆ€åÿ±Ÿá ŸÖ€å‚Äå⁄©ŸÜÿØ\n",
        "\n",
        "    def forward(self, inputs: List[float]) -> float:\n",
        "        \"\"\"\n",
        "        ÿÆÿ±Ÿàÿ¨€å ŸÜŸàÿ±ŸàŸÜ ÿ±ÿß ÿ®ÿß ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ Ÿàÿ±ŸàÿØ€å‚ÄåŸáÿß Ÿà Ÿàÿ≤ŸÜ‚ÄåŸáÿß ŸÖÿ≠ÿßÿ≥ÿ®Ÿá ŸÖ€å‚Äå⁄©ŸÜÿØ.\n",
        "\n",
        "        ÿ¢ÿ±⁄ØŸàŸÖÿßŸÜ‚ÄåŸáÿß:\n",
        "        inputs: ŸÑ€åÿ≥ÿ™€å ÿßÿ≤ Ÿàÿ±ŸàÿØ€å‚ÄåŸáÿß ÿ®Ÿá ŸÜŸàÿ±ŸàŸÜ.\n",
        "\n",
        "        ÿ®ÿ±ŸÖ€å‚Äå⁄Øÿ±ÿØÿßŸÜÿØ:\n",
        "        ÿÆÿ±Ÿàÿ¨€å ŸÜŸàÿ±ŸàŸÜ.\n",
        "        \"\"\"\n",
        "        self.inputs = inputs  # ÿ∞ÿÆ€åÿ±Ÿá Ÿàÿ±ŸàÿØ€å‚ÄåŸáÿß ÿ®ÿ±ÿß€å ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿØÿ± ŸÖÿ±ÿßÿ≠ŸÑ ÿ®ÿπÿØ€å\n",
        "        weighted_sum = sum([input_ * weight for input_, weight in zip(inputs, self.weights)])\n",
        "        self.output = weighted_sum + self.bias  # ÿ¨ŸÖÿπ ⁄©ÿ±ÿØŸÜ Ÿàÿ≤ŸÜ‚ÄåŸáÿß Ÿà ÿ®ÿß€åÿßÿ≥\n",
        "        return self.output\n",
        "\n",
        "    # def activation(self, output: float) -> float:\n",
        "    #     \"\"\"\n",
        "    #     ÿ™ÿßÿ®ÿπ ŸÅÿπÿßŸÑ‚Äåÿ≥ÿßÿ≤€å ÿ±ÿß ÿ®ÿ± ÿ±Ÿà€å ÿÆÿ±Ÿàÿ¨€å ŸÜŸàÿ±ŸàŸÜ ÿßÿπŸÖÿßŸÑ ŸÖ€å‚Äå⁄©ŸÜÿØ.\n",
        "\n",
        "    #     ÿØÿ± ÿß€åŸÜÿ¨ÿßÿå ÿ®Ÿá ÿ∑Ÿàÿ± ÿ≥ÿßÿØŸá ÿßÿ≤ ÿ™ÿßÿ®ÿπ ÿ≥€å⁄ØŸÖŸà€åÿØ ÿßÿ≥ÿ™ŸÅÿßÿØŸá ŸÖ€å‚Äå⁄©ŸÜ€åŸÖ.\n",
        "    #     \"\"\"\n",
        "\n",
        "    #     # ÿßÿ≤ ÿ™ÿßÿ®ÿπ ŸÅÿπÿßŸÑ‚Äåÿ≥ÿßÿ≤€å ÿ≥€å⁄ØŸÖŸà€åÿØ ÿßÿ≥ÿ™ŸÅÿßÿØŸá ŸÖ€å‚Äå⁄©ŸÜ€åŸÖ\n",
        "    #     return 1 / (1 + (2.718 ** -output))  # ÿß€åŸÜ €åÿπŸÜ€å ÿ≥€å⁄ØŸÖŸà€åÿØ\n",
        "\n",
        "    def activation(self, output: float) -> float:\n",
        "        return max(0, output)\n",
        "\n",
        "    def compute_gradient(self, delta: float) -> List[float]:\n",
        "        \"\"\"\n",
        "        ⁄Øÿ±ÿßÿØ€åÿßŸÜ ÿ®ÿ±ÿß€å Ÿàÿ≤ŸÜ‚ÄåŸáÿß ÿ±ÿß ÿ®ÿß ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ÿØŸÑÿ™ÿß (ÿ≥€å⁄ØŸÜÿßŸÑ ÿÆÿ∑ÿß€å ŸÑÿß€åŸá ÿ®ÿπÿØ€å) ŸÖÿ≠ÿßÿ≥ÿ®Ÿá ŸÖ€å‚Äå⁄©ŸÜÿØ.\n",
        "\n",
        "        ÿ¢ÿ±⁄ØŸàŸÖÿßŸÜ‚ÄåŸáÿß:\n",
        "        delta: ÿ≥€å⁄ØŸÜÿßŸÑ ÿÆÿ∑ÿß ÿßÿ≤ ŸÑÿß€åŸá ÿ®ÿπÿØ€å.\n",
        "\n",
        "        ÿ®ÿ±ŸÖ€å‚Äå⁄Øÿ±ÿØÿßŸÜÿØ:\n",
        "        ŸÑ€åÿ≥ÿ™€å ÿßÿ≤ ⁄Øÿ±ÿßÿØ€åÿßŸÜ‚ÄåŸáÿß ÿ®ÿ±ÿß€å Ÿáÿ± Ÿàÿ≤ŸÜ.\n",
        "        \"\"\"\n",
        "        gradients = [delta * input_ for input_ in self.inputs]  # ŸÖÿ≠ÿßÿ≥ÿ®Ÿá ⁄Øÿ±ÿßÿØ€åÿßŸÜ‚ÄåŸáÿß\n",
        "        return gradients\n",
        "\n",
        "    def update_weights(self, learning_rate: float, gradients: List[float]):\n",
        "        \"\"\"\n",
        "        Ÿàÿ≤ŸÜ‚ÄåŸáÿß Ÿà ÿ®ÿß€åÿßÿ≥ ŸÜŸàÿ±ŸàŸÜ ÿ±ÿß ÿ®ÿß ÿßÿ≥ÿ™ŸÅÿßÿØŸá ÿßÿ≤ ⁄Øÿ±ÿßÿØ€åÿßŸÜ‚ÄåŸáÿß Ÿà ŸÜÿ±ÿÆ €åÿßÿØ⁄Ø€åÿ±€å ÿ®Ÿá‚Äåÿ±Ÿàÿ≤ÿ±ÿ≥ÿßŸÜ€å ŸÖ€å‚Äå⁄©ŸÜÿØ.\n",
        "\n",
        "        ÿ¢ÿ±⁄ØŸàŸÖÿßŸÜ‚ÄåŸáÿß:\n",
        "        learning_rate: ŸÜÿ±ÿÆ €åÿßÿØ⁄Ø€åÿ±€å ÿ®ÿ±ÿß€å ÿ®Ÿá‚Äåÿ±Ÿàÿ≤ÿ±ÿ≥ÿßŸÜ€å Ÿàÿ≤ŸÜ‚ÄåŸáÿß.\n",
        "        gradients: ⁄Øÿ±ÿßÿØ€åÿßŸÜ‚ÄåŸáÿß€å ŸÖÿ≠ÿßÿ≥ÿ®Ÿá‚Äåÿ¥ÿØŸá ÿ®ÿ±ÿß€å Ÿáÿ± Ÿàÿ≤ŸÜ.\n",
        "        \"\"\"\n",
        "        # ÿ®Ÿá‚Äåÿ±Ÿàÿ≤ÿ±ÿ≥ÿßŸÜ€å Ÿàÿ≤ŸÜ‚ÄåŸáÿß\n",
        "        self.weights = [w - learning_rate * g for w, g in zip(self.weights, gradients)]\n",
        "        self.bias -= learning_rate * gradients[-1]  # ÿ®ÿß€åÿßÿ≥ ÿ±ÿß ŸÜ€åÿ≤ ÿ®Ÿá‚Äåÿ±Ÿàÿ≤ÿ±ÿ≥ÿßŸÜ€å ŸÖ€å‚Äå⁄©ŸÜ€åŸÖ\n",
        "\n",
        "    def propagate_error_back(self) -> List[float]:\n",
        "        \"\"\"\n",
        "        ÿß€åŸÜ ŸÖÿ™ÿØ ÿÆÿ∑ÿß€å ŸÜŸàÿ±ŸàŸÜ ÿ±Ÿà ÿ®ÿ±ÿß€å ŸÑÿß€åŸá ŸÇÿ®ŸÑ€å ÿ≠ÿ≥ÿßÿ® ŸÖ€å‚Äå⁄©ŸÜŸá.\n",
        "        €åÿπŸÜ€å ÿßŸàŸÑ ŸÖÿ¥ÿ™ŸÇ ÿ≥€å⁄ØŸÖŸà€åÿØ ÿ±Ÿà ÿßÿ≤ ÿÆÿ±Ÿàÿ¨€å ÿÆŸàÿØÿ¥ ŸÖ€å‚Äå⁄Ø€åÿ±Ÿáÿå\n",
        "        ÿ®ÿπÿØ ÿ®ÿß Ÿáÿ± Ÿàÿ≤ŸÜ ÿ∂ÿ±ÿ® ŸÖ€å‚Äå⁄©ŸÜŸá ÿ™ÿß ÿ®⁄ØŸá Ÿáÿ± Ÿàÿ±ŸàÿØ€å ⁄ÜŸÇÿØÿ± ÿØÿ± ÿÆÿ∑ÿß ÿ≥ŸáŸÖ ÿØÿßÿ±Ÿá.\n",
        "        \"\"\"\n",
        "        # ŸÖÿ¥ÿ™ŸÇ ÿ≥€å⁄ØŸÖŸà€åÿØ: output * (1 - output)\n",
        "        deriv = self.output * (1 - self.output)\n",
        "        # ÿ®ÿ±ÿß€å Ÿáÿ± Ÿàÿ≤ŸÜÿå ÿ≥ŸáŸÖ ÿÆÿ∑ÿß = ŸÖÿ¥ÿ™ŸÇ * Ÿàÿ≤ŸÜ\n",
        "        return [deriv * w for w in self.weights]"
      ],
      "metadata": {
        "id": "uJCkaPTT90u7"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ÿ™ÿ≥ÿ™ ÿπŸÖŸÑ⁄©ÿ±ÿØ ⁄©ŸÑÿßÿ≥ ŸÜŸàÿ±ŸàŸÜ\n",
        "\n",
        "# ÿß€åÿ¨ÿßÿØ €å⁄© ŸÜŸàÿ±ŸàŸÜ ÿ®ÿß Ÿàÿ≤ŸÜ‚ÄåŸáÿß Ÿà ÿ®ÿß€åÿßÿ≥ ÿ™ÿµÿßÿØŸÅ€å\n",
        "weights = [random.uniform(-1, 1) for _ in range(3)]  # ÿ≥Ÿá Ÿàÿ±ŸàÿØ€å ÿ®ÿß Ÿàÿ≤ŸÜ‚ÄåŸáÿß€å ÿ™ÿµÿßÿØŸÅ€å\n",
        "bias = random.uniform(-0.1, 0.1)  # ÿ®ÿß€åÿßÿ≥ ÿ™ÿµÿßÿØŸÅ€å\n",
        "neuron = Neuron(weights, bias)\n",
        "\n",
        "# Ÿàÿ±ŸàÿØ€å‚ÄåŸáÿß ÿ®ÿ±ÿß€å ŸÜŸàÿ±ŸàŸÜ\n",
        "inputs = [0.5, 0.2, 0.8]  # ÿ≥Ÿá Ÿàÿ±ŸàÿØ€å ÿ®ÿ±ÿß€å ŸÜŸàÿ±ŸàŸÜ\n",
        "\n",
        "# ŸÖÿ≠ÿßÿ≥ÿ®Ÿá ÿÆÿ±Ÿàÿ¨€å ŸÜŸàÿ±ŸàŸÜ\n",
        "output = neuron.forward(inputs)\n",
        "print(f\"ÿÆÿ±Ÿàÿ¨€å ŸÜŸàÿ±ŸàŸÜ ŸÇÿ®ŸÑ ÿßÿ≤ ŸÅÿπÿßŸÑ‚Äåÿ≥ÿßÿ≤€å: {output}\")\n",
        "\n",
        "# ÿßÿπŸÖÿßŸÑ ÿ™ÿßÿ®ÿπ ŸÅÿπÿßŸÑ‚Äåÿ≥ÿßÿ≤€å (ÿ≥€å⁄ØŸÖŸà€åÿØ)\n",
        "activated_output = neuron.activation(output)\n",
        "print(f\"ÿÆÿ±Ÿàÿ¨€å ŸÜŸàÿ±ŸàŸÜ ÿ®ÿπÿØ ÿßÿ≤ ŸÅÿπÿßŸÑ‚Äåÿ≥ÿßÿ≤€å: {activated_output}\")\n",
        "\n",
        "# ŸÅÿ±ÿ∂ ŸÖ€å‚Äå⁄©ŸÜ€åŸÖ ÿ≥€å⁄ØŸÜÿßŸÑ ÿÆÿ∑ÿß (ÿØŸÑÿ™ÿß) ÿ®ÿ±ÿßÿ®ÿ± 0.1 ÿßÿ≥ÿ™\n",
        "delta = 0.1\n",
        "gradients = neuron.compute_gradient(delta)\n",
        "print(f\"⁄Øÿ±ÿßÿØ€åÿßŸÜ‚ÄåŸáÿß€å ŸÖÿ≠ÿßÿ≥ÿ®Ÿá‚Äåÿ¥ÿØŸá ÿ®ÿ±ÿß€å Ÿàÿ≤ŸÜ‚ÄåŸáÿß: {gradients}\")\n",
        "\n",
        "# ÿ®Ÿá‚Äåÿ±Ÿàÿ≤ÿ±ÿ≥ÿßŸÜ€å Ÿàÿ≤ŸÜ‚ÄåŸáÿß ÿ®ÿß ŸÜÿ±ÿÆ €åÿßÿØ⁄Ø€åÿ±€å 0.01\n",
        "neuron.update_weights(learning_rate=0.01, gradients=gradients)\n",
        "print(f\"Ÿàÿ≤ŸÜ‚ÄåŸáÿß Ÿà ÿ®ÿß€åÿßÿ≥ ÿ®ÿπÿØ ÿßÿ≤ ÿ®Ÿá‚Äåÿ±Ÿàÿ≤ÿ±ÿ≥ÿßŸÜ€å: {neuron.weights}, {neuron.bias}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijZ-pMCIAScK",
        "outputId": "ec9777ae-406a-4ca0-b9b1-44a44d1ffe70"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÿÆÿ±Ÿàÿ¨€å ŸÜŸàÿ±ŸàŸÜ ŸÇÿ®ŸÑ ÿßÿ≤ ŸÅÿπÿßŸÑ‚Äåÿ≥ÿßÿ≤€å: -1.077792653702492\n",
            "ÿÆÿ±Ÿàÿ¨€å ŸÜŸàÿ±ŸàŸÜ ÿ®ÿπÿØ ÿßÿ≤ ŸÅÿπÿßŸÑ‚Äåÿ≥ÿßÿ≤€å: 0\n",
            "⁄Øÿ±ÿßÿØ€åÿßŸÜ‚ÄåŸáÿß€å ŸÖÿ≠ÿßÿ≥ÿ®Ÿá‚Äåÿ¥ÿØŸá ÿ®ÿ±ÿß€å Ÿàÿ≤ŸÜ‚ÄåŸáÿß: [0.05, 0.020000000000000004, 0.08000000000000002]\n",
            "Ÿàÿ≤ŸÜ‚ÄåŸáÿß Ÿà ÿ®ÿß€åÿßÿ≥ ÿ®ÿπÿØ ÿßÿ≤ ÿ®Ÿá‚Äåÿ±Ÿàÿ≤ÿ±ÿ≥ÿßŸÜ€å: [-0.9662690086364676, 0.6989679522511152, -0.9533296253659759], 0.026481960458299727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer:\n",
        "    \"\"\"€åŸá ŸÑÿß€åŸá ÿ™Ÿà€å ÿ¥ÿ®⁄©Ÿá ÿπÿµÿ®€å ⁄©Ÿá Ÿàÿ±ŸàÿØ€å‚ÄåŸáÿß ÿ±Ÿà ŸÖ€å‚Äå⁄Ø€åÿ±Ÿáÿå ŸÖ€å‚ÄåŸÅÿ±ÿ≥ÿ™Ÿá ÿ™Ÿà€å ŸÜŸàÿ±ŸàŸÜ‚ÄåŸáÿßÿå ŸÅÿπÿßŸÑ‚Äåÿ≥ÿßÿ≤€å ŸÖ€å‚Äå⁄©ŸÜŸá Ÿà ÿÆÿ±Ÿàÿ¨€å ŸÖ€å‚Äåÿ≥ÿßÿ≤Ÿá.\"\"\"\n",
        "\n",
        "    def __init__(self, neurons: List[Neuron], is_output_layer: bool = False):\n",
        "        \"\"\"\n",
        "        ÿ¢ÿ±⁄ØŸàŸÖÿßŸÜ‚ÄåŸáÿß:\n",
        "          neurons: ŸÑ€åÿ≥ÿ™€å ÿßÿ≤ ŸÜŸàÿ±ŸàŸÜ‚ÄåŸáÿß€å ÿß€åŸÜ ŸÑÿß€åŸá.\n",
        "          is_output_layer: ÿß⁄ØŸá True ÿ®ÿßÿ¥Ÿáÿå ÿß€åŸÜ ŸÑÿß€åŸá ÿ¢ÿÆÿ±Ÿá Ÿà ÿÆÿ±Ÿàÿ¨€å‚Äåÿ¥Ÿà ÿ®ÿß softmax ŸÖ€å‚Äåÿ≥ÿßÿ≤Ÿá.\n",
        "        \"\"\"\n",
        "        self.neurons = neurons\n",
        "        self.is_output_layer = is_output_layer\n",
        "\n",
        "    def forward(self, inputs: List[float]) -> List[float]:\n",
        "        \"\"\"\n",
        "        ÿØÿßÿØŸá‚ÄåŸáÿß ÿ±Ÿà ŸÖ€å‚ÄåŸÅÿ±ÿ≥ÿ™Ÿá ÿ™Ÿà€å Ÿáÿ± ŸÜŸàÿ±ŸàŸÜ Ÿà ÿÆÿ±Ÿàÿ¨€å ÿÆÿßŸÖ Ÿáÿ± ŸÜŸàÿ±ŸàŸÜ (logits) ÿ±Ÿà ŸÖ€å‚Äå⁄Ø€åÿ±Ÿá.\n",
        "        ÿ®ÿπÿØ ÿß⁄ØŸá ŸÑÿß€åŸá ÿ¢ÿÆÿ±€å ÿ®ÿßÿ¥Ÿá softmax ŸÖ€å‚Äåÿ≤ŸÜŸáÿõ Ÿà⁄Øÿ±ŸÜŸá ÿ®ÿß ŸÖÿ™ÿØ activation ÿÆŸàÿØ ŸÜŸàÿ±ŸàŸÜ ÿ≥€å⁄ØŸÖŸà€åÿØ ŸÖ€å‚Äåÿ≤ŸÜŸá.\n",
        "\n",
        "        inputs: ŸÑ€åÿ≥ÿ™ Ÿàÿ±ŸàÿØ€å ÿ®Ÿá ÿß€åŸÜ ŸÑÿß€åŸá (ŸÖÿ´ŸÑÿßŸã ÿÆÿ±Ÿàÿ¨€å ŸÑÿß€åŸá ŸÇÿ®ŸÑ€å).\n",
        "        ÿ®ÿ±ŸÖ€å‚Äå⁄Øÿ±ÿØŸàŸÜŸá: ŸÑ€åÿ≥ÿ™ ÿÆÿ±Ÿàÿ¨€å ŸÜŸáÿß€å€å ÿß€åŸÜ ŸÑÿß€åŸá.\n",
        "        \"\"\"\n",
        "        # logits €åÿπŸÜ€å ¬´ÿÆÿ±Ÿàÿ¨€å ÿÆÿßŸÖ ŸÜŸàÿ±ŸàŸÜ ŸÇÿ®ŸÑ ÿßÿ≤ ŸÅÿπÿßŸÑ‚Äåÿ≥ÿßÿ≤€å¬ª\n",
        "        logits = [neuron.forward(inputs) for neuron in self.neurons]\n",
        "\n",
        "        if self.is_output_layer:\n",
        "            # Ÿæ€åÿßÿØŸá‚Äåÿ≥ÿßÿ≤€å ÿØÿ≥ÿ™€å softmax: exp Ÿáÿ± ÿπÿØÿØ / ŸÖÿ¨ŸÖŸàÿπ expŸáÿß\n",
        "            # exp_vals = [math.exp(x) for x in logits]\n",
        "            # sum_exp = sum(exp_vals)\n",
        "            # return [v / sum_exp for v in exp_vals]\n",
        "            return self.softmax(logits)\n",
        "        else:\n",
        "            # ÿ®ÿ±ÿß€å ŸÑÿß€åŸá‚ÄåŸáÿß€å ŸÖ€åÿßŸÜ€å: Ÿáÿ± ŸÜŸàÿ±ŸàŸÜ ÿÆŸàÿØÿ¥ ŸÖÿ™ÿØ activation ÿØÿßÿ±Ÿá\n",
        "            return [neuron.activation(x) for neuron, x in zip(self.neurons, logits)]\n",
        "\n",
        "    def softmax(self, outputs: List[float]) -> List[float]:\n",
        "        exps = [math.exp(x) for x in outputs]\n",
        "        sum_exps = sum(exps)\n",
        "        return [exp / sum_exps for exp in exps]\n",
        "\n",
        "    def backward(self, delta: List[float], learning_rate: float) -> List[int]:\n",
        "        \"\"\"\n",
        "        ÿØŸÑÿ™ÿß (ÿÆÿ∑ÿß) ÿßÿ≤ ŸÑÿß€åŸá ÿ®ÿπÿØ€å ÿ±Ÿà ŸÖ€å‚Äå⁄Ø€åÿ±Ÿá Ÿà ÿ®ÿ±ÿß€å Ÿáÿ± ŸÜŸàÿ±ŸàŸÜ:\n",
        "        1. ÿ®ÿß compute_gradient ⁄Øÿ±ÿßÿØ€åÿßŸÜ‚ÄåŸáÿß ÿ±Ÿà ŸÖÿ≠ÿßÿ≥ÿ®Ÿá ŸÖ€å‚Äå⁄©ŸÜŸá\n",
        "        2. ÿ®ÿß update_weights Ÿàÿ≤ŸÜ Ÿà ÿ®ÿß€åÿßÿ≥ ÿ±Ÿà ÿ¢ŸæÿØ€åÿ™ ŸÖ€å‚Äå⁄©ŸÜŸá\n",
        "        3. ÿ®ÿß propagate_error_back ÿØŸÑÿ™ÿß€å ŸÖÿ±ÿ®Ÿàÿ∑ ÿ®Ÿá Ÿàÿ±ŸàÿØ€å‚ÄåŸáÿß ÿ±Ÿà ÿØÿ±€åÿßŸÅÿ™ ŸÖ€å‚Äå⁄©ŸÜŸá\n",
        "        ÿØÿ± ŸÜŸáÿß€åÿ™ ŸáŸÖŸá ÿØŸÑÿ™ÿßŸáÿß ÿ±Ÿà ÿ¨ŸÖÿπ ŸÖ€å‚Äå⁄©ŸÜŸá Ÿà ÿ®ÿ±ŸÖ€å‚Äå⁄Øÿ±ÿØŸàŸÜŸá ÿ®ÿ±ÿß€å ŸÑÿß€åŸá ŸÇÿ®ŸÑ€å.\n",
        "\n",
        "        delta: ŸÑ€åÿ≥ÿ™ ÿÆÿ∑ÿß ÿ®ÿ±ÿß€å Ÿáÿ± ŸÜŸàÿ±ŸàŸÜ ÿß€åŸÜ ŸÑÿß€åŸá\n",
        "        learning_rate: ŸÜÿ±ÿÆ €åÿßÿØ⁄Ø€åÿ±€å\n",
        "        ÿ®ÿ±ŸÖ€å‚Äå⁄Øÿ±ÿØŸàŸÜŸá: ŸÑ€åÿ≥ÿ™ delta ÿ®ÿ±ÿß€å ŸÑÿß€åŸá ŸÇÿ®ŸÑ€å\n",
        "        \"\"\"\n",
        "        propagated = []  # ÿß€åŸÜ ŸÑ€åÿ≥ÿ™ÿå Ÿáÿ± ÿπŸÜÿµÿ±ÿ¥ ŸÑ€åÿ≥ÿ™ ÿÆÿ∑ÿßŸáÿß€å€å‚Äå€åŸá ⁄©Ÿá Ÿáÿ± ŸÜŸàÿ±ŸàŸÜ ÿ®ÿ±ÿß€å Ÿàÿ±ŸàÿØ€å‚ÄåŸáÿß ÿ™ŸàŸÑ€åÿØ ŸÖ€å‚Äå⁄©ŸÜŸá\n",
        "\n",
        "        for i, neuron in enumerate(self.neurons):\n",
        "            # 1. ⁄Øÿ±ÿßÿØ€åÿßŸÜ ÿ±Ÿà ÿÆŸàÿØ ŸÜŸàÿ±ŸàŸÜ ŸÖÿ≠ÿßÿ≥ÿ®Ÿá ŸÖ€å‚Äå⁄©ŸÜŸá\n",
        "            grads = neuron.compute_gradient(delta[i])\n",
        "\n",
        "            # 2. ÿÆŸàÿØ ŸÜŸàÿ±ŸàŸÜ Ÿàÿ≤ŸÜ‚ÄåŸáÿß Ÿà ÿ®ÿß€åÿßÿ≥ ÿ±Ÿà ÿ¢ŸæÿØ€åÿ™ ŸÖ€å‚Äå⁄©ŸÜŸá\n",
        "            neuron.update_weights(learning_rate, grads)\n",
        "\n",
        "            # 3. ÿÆÿ∑ÿß ÿ®ÿ±ÿß€å Ÿàÿ±ŸàÿØ€å‚ÄåŸáÿß€å ŸÜŸàÿ±ŸàŸÜ (ÿ®ÿ±ÿß€å ŸÑÿß€åŸá ŸÇÿ®ŸÑ€å)\n",
        "            propagated.append(neuron.propagate_error_back())\n",
        "\n",
        "        # ÿ¨ŸÖÿπ ⁄©ÿ±ÿØŸÜ ÿØŸÑÿ™ÿßŸáÿß ÿ®ÿ±ÿß€å Ÿáÿ± Ÿàÿ±ŸàÿØ€å\n",
        "        # zip(*propagated) ÿ±ÿØ€åŸÅ‚ÄåŸáÿß ÿ±Ÿà ÿ≥ÿ™ŸàŸÜ€å ŸÖ€å‚Äå⁄©ŸÜŸá ÿ™ÿß ÿ®ÿ™ŸàŸÜ€åŸÖ ÿ¨ŸÖÿπ ⁄©ŸÜ€åŸÖ\n",
        "        prev_delta = [sum(x) for x in zip(*propagated)]\n",
        "        return prev_delta"
      ],
      "metadata": {
        "id": "JBJr0gtOE391"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neurons = [\n",
        "    Neuron(weights=[0.5, -0.4], bias=0.1),\n",
        "    Neuron(weights=[-1.0, 2.0], bias=0.2)\n",
        "]\n",
        "layer = Layer(neurons, is_output_layer=False)\n",
        "\n",
        "layer_output = layer.forward(inputs)\n",
        "print(\"ÿÆÿ±Ÿàÿ¨€å ŸÑÿß€åŸá:\", layer_output)\n",
        "\n",
        "delta = [0.1, -0.2]\n",
        "prev_delta = layer.backward(delta, learning_rate=0.01)\n",
        "print(\"ÿØŸÑÿ™ÿß ÿ®ÿ±ÿß€å ŸÑÿß€åŸá ŸÇÿ®ŸÑ€å:\", prev_delta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1y_V3HZ-PPVD",
        "outputId": "a7c434f9-64c1-4da8-aaa8-e796da234612"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÿÆÿ±Ÿàÿ¨€å ŸÑÿß€åŸá: [0.27, 0.10000000000000003]\n",
            "ÿØŸÑÿ™ÿß ÿ®ÿ±ÿß€å ŸÑÿß€åŸá ŸÇÿ®ŸÑ€å: [0.008541449999999978, 0.10115658000000005]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Network:\n",
        "    \"\"\"\n",
        "    €å⁄© ÿ¥ÿ®⁄©Ÿá‚Äå€å ÿπÿµÿ®€å ÿ≥ÿßÿØŸá ⁄©Ÿá ÿßÿ≤ ⁄ÜŸÜÿØ ŸÑÿß€åŸá ÿ™ÿ¥⁄©€åŸÑ ÿ¥ÿØŸá.\n",
        "    Ÿàÿ±ŸàÿØ€å ÿ±Ÿà ŸÖ€å‚Äå⁄Ø€åÿ±Ÿáÿå ÿßÿ≤ ÿ™Ÿà€å ŸÜŸàÿ±ŸàŸÜ‚ÄåŸáÿß ÿπÿ®Ÿàÿ± ŸÖ€å‚ÄåÿØŸáÿå Ÿà ÿÆÿ±Ÿàÿ¨€å ŸÜŸáÿß€å€å ÿ±Ÿà ÿ™ŸàŸÑ€åÿØ ŸÖ€å‚Äå⁄©ŸÜŸá.\n",
        "    ÿ®ÿπÿØÿ¥ ÿ®ÿß ÿ±Ÿàÿ¥ backpropagation Ÿàÿ≤ŸÜ‚ÄåŸáÿß ÿ±Ÿà ÿ¢ŸæÿØ€åÿ™ ŸÖ€å‚Äå⁄©ŸÜŸá.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, layers: List[Layer], epochs: int, learning_rate: float):\n",
        "        self.layers = layers\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def forward(self, inputs: List[float]) -> List[float]:\n",
        "        \"\"\"\n",
        "        Ÿàÿ±ŸàÿØ€å‚ÄåŸáÿß ÿ±Ÿà ÿßÿ≤ ÿ∑ÿ±€åŸÇ ŸáŸÖŸá‚Äå€å ŸÑÿß€åŸá‚ÄåŸáÿß ÿπÿ®Ÿàÿ± ŸÖ€å‚ÄåÿØŸá Ÿà ÿÆÿ±Ÿàÿ¨€å ŸÜŸáÿß€å€å ÿ±Ÿà ÿ≠ÿ≥ÿßÿ® ŸÖ€å‚Äå⁄©ŸÜŸá.\n",
        "        \"\"\"\n",
        "        outputs = inputs\n",
        "        for layer in self.layers:\n",
        "            outputs = layer.forward(outputs)\n",
        "        return outputs\n",
        "\n",
        "    def backward(self, targets: List[float], outputs: List[float]):\n",
        "        \"\"\"\n",
        "        ÿß€åŸÜ ÿ™ÿßÿ®ÿπ ÿÆÿ∑ÿß ÿ±Ÿà ÿßÿ≤ ÿÆÿ±Ÿàÿ¨€å ŸÜŸáÿß€å€å ŸÖÿ≠ÿßÿ≥ÿ®Ÿá ŸÖ€å‚Äå⁄©ŸÜŸá Ÿà ÿ®Ÿá ÿπŸÇÿ® ÿ®ÿ±ŸÖ€å‚Äå⁄Øÿ±ÿØŸàŸÜŸá ÿ™ÿß Ÿàÿ≤ŸÜ‚ÄåŸáÿß ÿ¢ŸæÿØ€åÿ™ ÿ®ÿ¥ŸÜ.\n",
        "        \"\"\"\n",
        "        delta = self.loss_derivative(outputs, targets)\n",
        "        for layer in reversed(self.layers):\n",
        "            delta = layer.backward(delta, self.learning_rate)\n",
        "\n",
        "    def compute_loss(self, predicted: List[float], actual: List[float]) -> float:\n",
        "        \"\"\"\n",
        "        ŸÖŸÇÿØÿßÿ± ÿÆÿ∑ÿß ÿ±Ÿà ÿ®€åŸÜ ÿÆÿ±Ÿàÿ¨€å Ÿæ€åÿ¥‚Äåÿ®€åŸÜ€å‚Äåÿ¥ÿØŸá Ÿà ŸÖŸÇÿØÿßÿ± ŸàÿßŸÇÿπ€å ÿ≠ÿ≥ÿßÿ® ŸÖ€å‚Äå⁄©ŸÜŸá.\n",
        "        \"\"\"\n",
        "        return LossFunction.cross_entropy(predicted, actual)\n",
        "\n",
        "    def loss_derivative(self, outputs: List[float], targets: List[float]) -> List[float]:\n",
        "        \"\"\"\n",
        "        ŸÖÿ¥ÿ™ŸÇ ÿ™ÿßÿ®ÿπ ÿÆÿ∑ÿß ÿ±Ÿà ÿ≠ÿ≥ÿßÿ® ŸÖ€å‚Äå⁄©ŸÜŸáÿå €åÿπŸÜ€å ÿßÿÆÿ™ŸÑÿßŸÅ ÿ®€åŸÜ ÿÆÿ±Ÿàÿ¨€å ŸÖÿØŸÑ Ÿà ŸÖŸÇÿØÿßÿ± ÿØÿ±ÿ≥ÿ™.\n",
        "        \"\"\"\n",
        "        return [pred - target for pred, target in zip(outputs, targets)]\n",
        "\n",
        "    def train(self, training_data: List[tuple]):\n",
        "        \"\"\"\n",
        "        ÿ¥ÿ®⁄©Ÿá ÿ±Ÿà ÿ®ÿß ÿØÿßÿØŸá‚ÄåŸáÿß€å ÿ¢ŸÖŸàÿ≤ÿ¥€å ÿ¢ŸÖŸàÿ≤ÿ¥ ŸÖ€å‚ÄåÿØŸá. Ÿáÿ± ÿ®ÿßÿ± Ÿàÿ≤ŸÜ‚ÄåŸáÿß ÿ±Ÿà ÿ¢ŸæÿØ€åÿ™ ŸÖ€å‚Äå⁄©ŸÜŸá.\n",
        "        \"\"\"\n",
        "        num_samples = len(training_data)\n",
        "        for epoch in range(self.epochs):\n",
        "            total_loss = 0\n",
        "            random.shuffle(training_data)\n",
        "\n",
        "            for inputs, targets in training_data:\n",
        "                outputs = self.forward(inputs)\n",
        "                loss = self.compute_loss(outputs, targets)\n",
        "                total_loss += loss\n",
        "                self.backward(targets, outputs)\n",
        "\n",
        "            avg_loss = total_loss / num_samples\n",
        "            print(f\"Epoch {epoch + 1}/{self.epochs} complete. Average loss: {avg_loss:.4f}\")\n",
        "\n",
        "    def evaluate(self, test_data: List[tuple]) -> float:\n",
        "        \"\"\"\n",
        "        ÿØŸÇÿ™ ŸÖÿØŸÑ ÿ±Ÿà ÿ®ÿß ÿØÿßÿØŸá‚ÄåŸáÿß€å ÿ™ÿ≥ÿ™ ÿ≠ÿ≥ÿßÿ® ŸÖ€å‚Äå⁄©ŸÜŸá.\n",
        "        \"\"\"\n",
        "        inputs_batch, targets_batch = zip(*test_data)\n",
        "        predictions = [self.forward(inputs) for inputs in inputs_batch]\n",
        "        accuracy = self.calculate_accuracy(predictions, targets_batch)\n",
        "        return accuracy\n",
        "\n",
        "    def predict(self, new_data: List[float]) -> List[float]:\n",
        "        \"\"\"\n",
        "        ÿ®ÿ±ÿß€å €å⁄© Ÿàÿ±ŸàÿØ€å ÿ¨ÿØ€åÿØÿå ÿÆÿ±Ÿàÿ¨€å ŸÖÿØŸÑ ÿ±Ÿà Ÿæ€åÿ¥‚Äåÿ®€åŸÜ€å ŸÖ€å‚Äå⁄©ŸÜŸá.\n",
        "        \"\"\"\n",
        "        return self.forward(new_data)\n",
        "\n",
        "    def calculate_accuracy(self, predictions: List[List[float]], targets: List[List[float]]) -> float:\n",
        "        \"\"\"\n",
        "        ÿØŸÇÿ™ Ÿæ€åÿ¥‚Äåÿ®€åŸÜ€å ŸÖÿØŸÑ ÿ±Ÿà ŸÜÿ≥ÿ®ÿ™ ÿ®Ÿá ŸÖŸÇÿØÿßÿ± ÿØÿ±ÿ≥ÿ™ ÿ≠ÿ≥ÿßÿ® ŸÖ€å‚Äå⁄©ŸÜŸá.\n",
        "        \"\"\"\n",
        "        correct_predictions = 0\n",
        "        for pred, target in zip(predictions, targets):\n",
        "            predicted_class = np.argmax(pred)\n",
        "            true_class = np.argmax(target)\n",
        "            if predicted_class == true_class:\n",
        "                correct_predictions += 1\n",
        "        return correct_predictions / len(targets)\n",
        "\n",
        "    def save_weights(self, filename: str):\n",
        "        \"\"\"\n",
        "        Ÿàÿ≤ŸÜ‚ÄåŸáÿß Ÿà ÿ®ÿß€åÿßÿ≥‚ÄåŸáÿß€å ŸÜŸàÿ±ŸàŸÜ‚ÄåŸáÿß ÿ±Ÿà ÿ™Ÿà€å €åŸá ŸÅÿß€åŸÑ ÿ∞ÿÆ€åÿ±Ÿá ŸÖ€å‚Äå⁄©ŸÜŸá ÿ™ÿß ÿ®ÿπÿØÿß ÿ®ÿ¥Ÿá ÿØŸàÿ®ÿßÿ±Ÿá ÿ®ÿßÿ±⁄Øÿ∞ÿßÿ±€åÿ¥ŸàŸÜ ⁄©ÿ±ÿØ.\n",
        "        \"\"\"\n",
        "        weights = [[neuron.weights for neuron in layer.neurons] for layer in self.layers]\n",
        "        biases = [[neuron.bias for neuron in layer.neurons] for layer in self.layers]\n",
        "        with open(filename, 'wb') as f:\n",
        "            pickle.dump((weights, biases), f)\n",
        "\n",
        "    def load_weights(self, filename: str):\n",
        "        \"\"\"\n",
        "        Ÿàÿ≤ŸÜ‚ÄåŸáÿß Ÿà ÿ®ÿß€åÿßÿ≥‚ÄåŸáÿß ÿ±Ÿà ÿßÿ≤ ŸÅÿß€åŸÑ ŸÖ€å‚ÄåÿÆŸàŸÜŸá Ÿà ÿ®Ÿá ÿ¥ÿ®⁄©Ÿá ÿßÿÆÿ™ÿµÿßÿµ ŸÖ€å‚ÄåÿØŸá.\n",
        "        \"\"\"\n",
        "        with open(filename, 'rb') as f:\n",
        "            weights, biases = pickle.load(f)\n",
        "        for layer, layer_weights, layer_biases in zip(self.layers, weights, biases):\n",
        "            for neuron, w, b in zip(layer.neurons, layer_weights, layer_biases):\n",
        "                neuron.weights = w\n",
        "                neuron.bias = b\n"
      ],
      "metadata": {
        "id": "g3Jq30B-J1Lk"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LossFunction:\n",
        "    \"\"\"⁄©ŸÑÿßÿ≥€å ÿ®ÿ±ÿß€å ŸÖÿ≠ÿßÿ≥ÿ®Ÿá ÿßŸÜŸàÿßÿπ ÿ™ÿßÿ®ÿπ Ÿáÿ≤€åŸÜŸá.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def cross_entropy(predicted_outputs: List[float], actual_outputs: List[float]) -> float:\n",
        "        \"\"\"\n",
        "        üîπ ÿß€åŸÜ ÿ™ÿßÿ®ÿπ ÿ®ÿ±ÿß€å classification ÿßÿ≥ÿ™ŸÅÿßÿØŸá ŸÖ€å‚Äåÿ¥Ÿáÿå ŸÖÿÆÿµŸàÿµÿßŸã ŸàŸÇÿ™€å ÿÆÿ±Ÿàÿ¨€å‚ÄåŸáÿß one-hot Ÿáÿ≥ÿ™ŸÜ.\n",
        "        üîπ ÿßÿ≤ ŸÑ⁄Øÿßÿ±€åÿ™ŸÖ ÿßÿ≥ÿ™ŸÅÿßÿØŸá ŸÖ€å‚Äå⁄©ŸÜŸá ÿ™ÿß ÿ™ŸÅÿßŸàÿ™ ÿ®€åŸÜ ÿßÿ≠ÿ™ŸÖÿßŸÑ Ÿæ€åÿ¥‚Äåÿ®€åŸÜ€å‚Äåÿ¥ÿØŸá Ÿà ŸÖŸÇÿØÿßÿ± ŸàÿßŸÇÿπ€å ÿ±Ÿà ÿ®ÿ≥ŸÜÿ¨Ÿá.\n",
        "        \"\"\"\n",
        "        predicted_outputs = np.clip(predicted_outputs, 1e-12, 1 - 1e-12)\n",
        "        loss = -sum([actual * np.log(pred) for pred, actual in zip(predicted_outputs, actual_outputs)])\n",
        "        return loss / len(predicted_outputs)\n",
        "\n",
        "    @staticmethod\n",
        "    def mean_squared_error(predicted_outputs: List[float], actual_outputs: List[float]) -> float:\n",
        "        \"\"\"\n",
        "        üî∏ ÿß€åŸÜ ÿ™ÿßÿ®ÿπ ÿ®ÿ±ÿß€å regression ÿßÿ≥ÿ™ŸÅÿßÿØŸá ŸÖ€å‚Äåÿ¥Ÿá.\n",
        "        üî∏ ÿÆÿ∑ÿß€å ŸÖÿ±ÿ®ÿπ€å ÿ®€åŸÜ Ÿæ€åÿ¥‚Äåÿ®€åŸÜ€å Ÿà ŸÖŸÇÿØÿßÿ± ŸàÿßŸÇÿπ€å ÿ±Ÿà ŸÖÿ≠ÿßÿ≥ÿ®Ÿá ŸÖ€å‚Äå⁄©ŸÜŸá.\n",
        "        \"\"\"\n",
        "        squared_errors = [(pred - actual) ** 2 for pred, actual in zip(predicted_outputs, actual_outputs)]\n",
        "        return sum(squared_errors) / len(squared_errors)\n"
      ],
      "metadata": {
        "id": "anKsHgS8N-Iv"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WeightsInitializer:\n",
        "    \"\"\"⁄©ŸÑÿßÿ≥€å ÿ®ÿ±ÿß€å ŸÖŸÇÿØÿßÿ±ÿØŸá€å ÿßŸàŸÑ€åŸá ÿ®Ÿá Ÿàÿ≤ŸÜ‚ÄåŸáÿß.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def random_uniform(num_inputs: int) -> List[float]:\n",
        "        \"\"\"\n",
        "        üîπ ŸÖŸÇÿØÿßÿ±ÿØŸá€å ÿßŸàŸÑ€åŸá ÿ®Ÿá Ÿàÿ≤ŸÜ‚ÄåŸáÿß ÿ®Ÿá ÿµŸàÿ±ÿ™ ÿ™ÿµÿßÿØŸÅ€å ÿ®€åŸÜ -0.1 ÿ™ÿß 0.1.\n",
        "        üîπ ÿ®ÿ±ÿß€å ÿß€åŸÜ⁄©Ÿá ÿ¥ÿ®⁄©Ÿá ÿßÿ≤ ÿµŸÅÿ± ÿ¥ÿ±Ÿàÿπ ŸÜ⁄©ŸÜŸá Ÿà ÿ®ÿ™ŸàŸÜŸá ŸÖÿ≥€åÿ± €åÿßÿØ⁄Ø€åÿ±€å Ÿæ€åÿØÿß ⁄©ŸÜŸá.\n",
        "        \"\"\"\n",
        "        return [random.uniform(-0.5, 0.5) for _ in range(num_inputs)]\n"
      ],
      "metadata": {
        "id": "da7SbIFhuipG"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Workflow üîÆ: Architecture"
      ],
      "metadata": {
        "id": "Iz1cl6tesGG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encode(labels: list) -> list:\n",
        "    # Create a consistent label-to-index mapping\n",
        "    unique_labels = sorted(set(labels))\n",
        "    label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "    print(\"Label to Index Mapping:\")\n",
        "    for label, index in label_to_index.items():\n",
        "        print(f\"  {label}: {index}\")\n",
        "\n",
        "    # One-hot encode each label\n",
        "    encoded = []\n",
        "    for label in labels:\n",
        "        vec = [0] * len(unique_labels)\n",
        "        vec[label_to_index[label]] = 1\n",
        "        encoded.append(vec)\n",
        "\n",
        "    # Optional: show a sample\n",
        "    print(\"\\nSample One-Hot Encoded Vectors:\")\n",
        "    for i in range(min(3, len(encoded))):\n",
        "        print(f\"  {labels[i]} => {encoded[i]}\")\n",
        "\n",
        "    return encoded\n"
      ],
      "metadata": {
        "id": "HBiYFcTcaJ-C"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create input layer"
      ],
      "metadata": {
        "id": "r5fEpiz3swJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/Colab Notebooks/Iris Classification/Iris.csv'\n",
        "test_data_loading(file_path)\n",
        "\n",
        "data, labels = load_dataset(file_path)\n",
        "labels = one_hot_encode(labels)\n",
        "data = min_max_normalizer(data)\n",
        "\n",
        "\n",
        "dataset = list(zip(data, labels))\n",
        "test_split_data()\n",
        "train, val, test = split_data(dataset, training_size=0.5, validation_size=0.0)\n",
        "training_data, validation_data, test_data = split_data(dataset)\n",
        "\n",
        "print(training_data)\n",
        "print(validation_data)\n",
        "print(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HQOh2Wko-KW",
        "outputId": "85a2c2c2-3b90-4615-8951-865ef956a69b"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded and validated successfully.\n",
            "Label to Index Mapping:\n",
            "  Iris-setosa: 0\n",
            "  Iris-versicolor: 1\n",
            "  Iris-virginica: 2\n",
            "\n",
            "Sample One-Hot Encoded Vectors:\n",
            "  Iris-setosa => [1, 0, 0]\n",
            "  Iris-setosa => [1, 0, 0]\n",
            "  Iris-setosa => [1, 0, 0]\n",
            "‚ùå ÿ™ÿ≥ÿ™ ÿ¥⁄©ÿ≥ÿ™ ÿÆŸàÿ±ÿØ: ÿÆÿ∑ÿß ÿØÿ± ÿ™ŸÇÿ≥€åŸÖ ÿØ€åÿ™ÿß: ÿ™ÿπÿØÿßÿØ ŸÜŸáÿß€å€å ÿ®ÿß ÿßŸàŸÑ€åŸá ŸÜŸÖ€å‚ÄåÿÆŸàŸÜŸá.\n",
            "[([0.8456375838926175, 0.5277777777777778, 0.3333333333333332, 0.6440677966101694, 0.7083333333333334], [0, 0, 1]), ([0.4966442953020134, 0.5833333333333334, 0.3749999999999999, 0.559322033898305, 0.5], [0, 1, 0]), ([0.2080536912751678, 0.30555555555555564, 0.5833333333333333, 0.0847457627118644, 0.12500000000000003], [1, 0, 0]), ([0.8523489932885906, 0.4999999999999999, 0.41666666666666663, 0.6610169491525424, 0.7083333333333334], [0, 0, 1]), ([0.47651006711409394, 0.4999999999999999, 0.3333333333333332, 0.5084745762711864, 0.5], [0, 1, 0]), ([0.4161073825503356, 0.4722222222222222, 0.0833333333333334, 0.5084745762711864, 0.375], [0, 1, 0]), ([0.1342281879194631, 0.30555555555555564, 0.5833333333333333, 0.11864406779661016, 0.04166666666666667], [1, 0, 0]), ([0.1610738255033557, 0.13888888888888887, 0.5833333333333333, 0.15254237288135591, 0.04166666666666667], [1, 0, 0]), ([0.31543624161073824, 0.08333333333333327, 0.5, 0.06779661016949151, 0.04166666666666667], [1, 0, 0]), ([0.24161073825503357, 0.3333333333333333, 0.6249999999999999, 0.05084745762711865, 0.04166666666666667], [1, 0, 0]), ([0.8389261744966443, 0.8055555555555556, 0.5, 0.847457627118644, 0.7083333333333334], [0, 0, 1]), ([0.18120805369127516, 0.25000000000000006, 0.6249999999999999, 0.0847457627118644, 0.04166666666666667], [1, 0, 0]), ([0.7583892617449665, 0.38888888888888895, 0.20833333333333331, 0.6779661016949152, 0.7916666666666666], [0, 0, 1]), ([0.8859060402684564, 0.5833333333333334, 0.3333333333333332, 0.7796610169491525, 0.8750000000000001], [0, 0, 1]), ([0.9530201342281879, 0.41666666666666663, 0.2916666666666667, 0.6949152542372881, 0.75], [0, 0, 1]), ([0.5570469798657718, 0.4722222222222222, 0.2916666666666667, 0.6949152542372881, 0.625], [0, 1, 0]), ([0.348993288590604, 0.7222222222222222, 0.4583333333333333, 0.6610169491525424, 0.5833333333333334], [0, 1, 0]), ([0.6241610738255033, 0.19444444444444448, 0.1249999999999999, 0.38983050847457623, 0.375], [0, 1, 0]), ([0.8322147651006712, 0.6666666666666666, 0.5416666666666665, 0.7966101694915254, 0.8333333333333334], [0, 0, 1]), ([0.48322147651006714, 0.5555555555555555, 0.20833333333333331, 0.6610169491525424, 0.5833333333333334], [0, 1, 0]), ([0.697986577181208, 0.611111111111111, 0.41666666666666663, 0.8135593220338982, 0.8750000000000001], [0, 0, 1]), ([0.9261744966442953, 0.4722222222222222, 0.41666666666666663, 0.6440677966101694, 0.7083333333333334], [0, 0, 1]), ([0.35570469798657717, 0.3333333333333333, 0.1249999999999999, 0.5084745762711864, 0.5], [0, 1, 0]), ([0.785234899328859, 0.9444444444444444, 0.7499999999999998, 0.9661016949152542, 0.8750000000000001], [0, 0, 1]), ([0.22818791946308725, 0.1666666666666668, 0.4583333333333333, 0.0847457627118644, 0.0], [1, 0, 0]), ([0.7651006711409396, 0.41666666666666663, 0.3333333333333332, 0.6949152542372881, 0.9583333333333333], [0, 0, 1]), ([0.6510067114093959, 0.5277777777777778, 0.3749999999999999, 0.559322033898305, 0.5], [0, 1, 0]), ([0.5704697986577181, 0.4722222222222222, 0.5833333333333333, 0.5932203389830508, 0.625], [0, 1, 0]), ([0.436241610738255, 0.6666666666666666, 0.4583333333333333, 0.576271186440678, 0.5416666666666666], [0, 1, 0]), ([0.14093959731543623, 0.22222222222222213, 0.7083333333333333, 0.0847457627118644, 0.12500000000000003], [1, 0, 0]), ([0.040268456375838924, 0.08333333333333327, 0.5833333333333333, 0.06779661016949151, 0.08333333333333333], [1, 0, 0]), ([0.8053691275167785, 0.7222222222222222, 0.5, 0.7966101694915254, 0.9166666666666666], [0, 0, 1]), ([0.11409395973154363, 0.22222222222222213, 0.6249999999999999, 0.06779661016949151, 0.08333333333333333], [1, 0, 0]), ([0.06040268456375839, 0.1666666666666668, 0.4583333333333333, 0.0847457627118644, 0.0], [1, 0, 0]), ([0.16778523489932887, 0.19444444444444448, 0.41666666666666663, 0.1016949152542373, 0.04166666666666667], [1, 0, 0]), ([0.5771812080536913, 0.6666666666666666, 0.4583333333333333, 0.6271186440677966, 0.5833333333333334], [0, 1, 0]), ([0.2751677852348993, 0.055555555555555594, 0.1249999999999999, 0.05084745762711865, 0.08333333333333333], [1, 0, 0]), ([0.5302013422818792, 0.38888888888888895, 0.25, 0.423728813559322, 0.375], [0, 1, 0]), ([0.912751677852349, 0.5555555555555555, 0.5833333333333333, 0.7796610169491525, 0.9583333333333333], [0, 0, 1]), ([0.6040268456375839, 0.3333333333333333, 0.25, 0.576271186440678, 0.4583333333333333], [0, 1, 0]), ([0.5838926174496645, 0.5555555555555555, 0.1249999999999999, 0.576271186440678, 0.5], [0, 1, 0]), ([0.4697986577181208, 0.44444444444444453, 0.5, 0.6440677966101694, 0.7083333333333334], [0, 1, 0]), ([0.4429530201342282, 0.361111111111111, 0.41666666666666663, 0.5932203389830508, 0.5833333333333334], [0, 1, 0]), ([0.9060402684563759, 0.9444444444444444, 0.41666666666666663, 0.8644067796610169, 0.9166666666666666], [0, 0, 1]), ([0.026845637583892617, 0.19444444444444448, 0.6666666666666666, 0.06779661016949151, 0.04166666666666667], [1, 0, 0]), ([0.1476510067114094, 0.08333333333333327, 0.6666666666666666, 0.0, 0.04166666666666667], [1, 0, 0]), ([0.7449664429530202, 0.5833333333333334, 0.2916666666666667, 0.7288135593220338, 0.75], [0, 0, 1]), ([0.6174496644295302, 0.41666666666666663, 0.25, 0.5084745762711864, 0.4583333333333333], [0, 1, 0]), ([0.8657718120805369, 0.8055555555555556, 0.41666666666666663, 0.8135593220338982, 0.625], [0, 0, 1]), ([0.46308724832214765, 0.361111111111111, 0.20833333333333331, 0.4915254237288135, 0.4166666666666667], [0, 1, 0]), ([0.9664429530201343, 0.6666666666666666, 0.5416666666666665, 0.7966101694915254, 1.0], [0, 0, 1]), ([0.959731543624161, 0.6944444444444443, 0.5, 0.8305084745762712, 0.9166666666666666], [0, 0, 1]), ([0.3624161073825503, 0.611111111111111, 0.3333333333333332, 0.6101694915254237, 0.5833333333333334], [0, 1, 0]), ([0.7114093959731543, 0.1666666666666668, 0.20833333333333331, 0.5932203389830508, 0.6666666666666666], [0, 0, 1]), ([0.8926174496644296, 0.5555555555555555, 0.3333333333333332, 0.6949152542372881, 0.5833333333333334], [0, 0, 1]), ([0.6845637583892618, 0.7777777777777776, 0.41666666666666663, 0.8305084745762712, 0.8333333333333334], [0, 0, 1]), ([0.3422818791946309, 0.5833333333333334, 0.5, 0.5932203389830508, 0.5833333333333334], [0, 1, 0]), ([0.6778523489932886, 0.41666666666666663, 0.2916666666666667, 0.6949152542372881, 0.75], [0, 0, 1]), ([0.42953020134228187, 0.361111111111111, 0.3749999999999999, 0.4406779661016949, 0.5], [0, 1, 0]), ([0.40939597315436244, 0.44444444444444453, 0.41666666666666663, 0.5423728813559322, 0.5833333333333334], [0, 1, 0]), ([0.40268456375838924, 0.19444444444444448, 0.0, 0.423728813559322, 0.375], [0, 1, 0]), ([0.5503355704697986, 0.41666666666666663, 0.2916666666666667, 0.4915254237288135, 0.4583333333333333], [0, 1, 0]), ([0.3691275167785235, 0.38888888888888895, 0.3333333333333332, 0.5932203389830508, 0.5], [0, 1, 0]), ([0.9798657718120806, 0.5555555555555555, 0.20833333333333331, 0.6779661016949152, 0.75], [0, 0, 1]), ([0.12080536912751678, 0.38888888888888895, 0.7499999999999998, 0.11864406779661016, 0.08333333333333333], [1, 0, 0]), ([0.9731543624161074, 0.6666666666666666, 0.41666666666666663, 0.711864406779661, 0.9166666666666666], [0, 0, 1]), ([0.37583892617449666, 0.5555555555555555, 0.5416666666666665, 0.6271186440677966, 0.625], [0, 1, 0]), ([0.44966442953020136, 0.41666666666666663, 0.2916666666666667, 0.5254237288135593, 0.375], [0, 1, 0]), ([0.3959731543624161, 0.25000000000000006, 0.2916666666666667, 0.4915254237288135, 0.5416666666666666], [0, 1, 0]), ([0.9395973154362416, 0.6666666666666666, 0.4583333333333333, 0.7796610169491525, 0.9583333333333333], [0, 0, 1]), ([0.87248322147651, 0.8611111111111112, 0.3333333333333332, 0.8644067796610169, 0.75], [0, 0, 1]), ([0.8590604026845637, 0.5833333333333334, 0.3333333333333332, 0.7796610169491525, 0.8333333333333334], [0, 0, 1]), ([0.5234899328859061, 0.4722222222222222, 0.3749999999999999, 0.5932203389830508, 0.5833333333333334], [0, 1, 0]), ([0.6644295302013423, 0.38888888888888895, 0.3333333333333332, 0.5254237288135593, 0.5], [0, 1, 0]), ([0.4563758389261745, 0.5277777777777778, 0.0833333333333334, 0.5932203389830508, 0.5833333333333334], [0, 1, 0]), ([0.4899328859060403, 0.4999999999999999, 0.3333333333333332, 0.6271186440677966, 0.4583333333333333], [0, 1, 0]), ([0.738255033557047, 0.611111111111111, 0.5, 0.6949152542372881, 0.7916666666666666], [0, 0, 1]), ([0.5637583892617449, 0.30555555555555564, 0.41666666666666663, 0.5932203389830508, 0.5833333333333334], [0, 1, 0]), ([0.6711409395973155, 0.5555555555555555, 0.5416666666666665, 0.847457627118644, 1.0], [0, 0, 1]), ([0.20134228187919462, 0.13888888888888887, 0.4583333333333333, 0.1016949152542373, 0.04166666666666667], [1, 0, 0]), ([0.0738255033557047, 0.13888888888888887, 0.5833333333333333, 0.1016949152542373, 0.04166666666666667], [1, 0, 0]), ([0.2214765100671141, 0.3333333333333333, 0.9166666666666666, 0.06779661016949151, 0.04166666666666667], [1, 0, 0]), ([0.09395973154362416, 0.41666666666666663, 0.8333333333333333, 0.033898305084745756, 0.04166666666666667], [1, 0, 0]), ([0.2483221476510067, 0.1666666666666668, 0.4583333333333333, 0.0847457627118644, 0.0], [1, 0, 0]), ([0.6912751677852349, 0.5555555555555555, 0.3749999999999999, 0.7796610169491525, 0.7083333333333334], [0, 0, 1]), ([0.04697986577181208, 0.19444444444444448, 0.5833333333333333, 0.0847457627118644, 0.04166666666666667], [1, 0, 0]), ([0.5973154362416108, 0.3333333333333333, 0.20833333333333331, 0.5084745762711864, 0.5], [0, 1, 0]), ([0.08053691275167785, 0.13888888888888887, 0.41666666666666663, 0.06779661016949151, 0.0], [1, 0, 0]), ([0.7718120805369127, 0.5833333333333334, 0.5, 0.7288135593220338, 0.9166666666666666], [0, 0, 1]), ([0.7919463087248322, 0.9444444444444444, 0.25, 1.0, 0.9166666666666666], [0, 0, 1]), ([0.8187919463087249, 0.9444444444444444, 0.3333333333333332, 0.9661016949152542, 0.7916666666666666], [0, 0, 1]), ([0.7181208053691275, 0.8333333333333333, 0.3749999999999999, 0.8983050847457626, 0.7083333333333334], [0, 0, 1]), ([0.10067114093959731, 0.38888888888888895, 1.0, 0.0847457627118644, 0.12500000000000003], [1, 0, 0]), ([0.26174496644295303, 0.22222222222222213, 0.5833333333333333, 0.0847457627118644, 0.04166666666666667], [1, 0, 0]), ([0.5369127516778524, 0.3333333333333333, 0.1666666666666666, 0.47457627118644063, 0.4166666666666667], [0, 1, 0]), ([0.4228187919463087, 0.4999999999999999, 0.3749999999999999, 0.6271186440677966, 0.5416666666666666], [0, 1, 0]), ([0.825503355704698, 0.5555555555555555, 0.2916666666666667, 0.6610169491525424, 0.7083333333333334], [0, 0, 1]), ([0.7248322147651006, 0.6666666666666666, 0.20833333333333331, 0.8135593220338982, 0.7083333333333334], [0, 0, 1]), ([0.19463087248322147, 0.11111111111111119, 0.5, 0.1016949152542373, 0.04166666666666667], [1, 0, 0]), ([0.9194630872483222, 0.5833333333333334, 0.4583333333333333, 0.7627118644067796, 0.7083333333333334], [0, 0, 1]), ([0.087248322147651, 0.0, 0.41666666666666663, 0.016949152542372895, 0.0], [1, 0, 0]), ([0.2348993288590604, 0.19444444444444448, 0.5, 0.033898305084745756, 0.04166666666666667], [1, 0, 0]), ([0.06711409395973154, 0.30555555555555564, 0.7083333333333333, 0.0847457627118644, 0.04166666666666667], [1, 0, 0]), ([0.38926174496644295, 0.6388888888888887, 0.3749999999999999, 0.6101694915254237, 0.5], [0, 1, 0]), ([0.8993288590604027, 0.4999999999999999, 0.25, 0.7796610169491525, 0.5416666666666666], [0, 0, 1])]\n",
            "[[]]\n",
            "[([0.3288590604026846, 0.19444444444444448, 0.5416666666666665, 0.06779661016949151, 0.04166666666666667], [1, 0, 0]), ([0.3087248322147651, 0.22222222222222213, 0.7499999999999998, 0.1016949152542373, 0.04166666666666667], [1, 0, 0]), ([0.053691275167785234, 0.027777777777777922, 0.3749999999999999, 0.06779661016949151, 0.04166666666666667], [1, 0, 0]), ([0.12751677852348994, 0.22222222222222213, 0.7499999999999998, 0.0847457627118644, 0.08333333333333333], [1, 0, 0]), ([0.2550335570469799, 0.027777777777777922, 0.41666666666666663, 0.05084745762711865, 0.04166666666666667], [1, 0, 0]), ([0.020134228187919462, 0.08333333333333327, 0.4583333333333333, 0.0847457627118644, 0.04166666666666667], [1, 0, 0]), ([0.013422818791946308, 0.11111111111111119, 0.5, 0.05084745762711865, 0.04166666666666667], [1, 0, 0]), ([0.8120805369127517, 0.361111111111111, 0.3333333333333332, 0.6610169491525424, 0.7916666666666666], [0, 0, 1]), ([0.33557046979865773, 0.7499999999999999, 0.5, 0.6271186440677966, 0.5416666666666666], [0, 1, 0]), ([0.2684563758389262, 0.19444444444444448, 0.6249999999999999, 0.05084745762711865, 0.08333333333333333], [1, 0, 0]), ([0.2953020134228188, 0.22222222222222213, 0.7499999999999998, 0.15254237288135591, 0.12500000000000003], [1, 0, 0]), ([0.30201342281879195, 0.13888888888888887, 0.41666666666666663, 0.06779661016949151, 0.08333333333333333], [1, 0, 0]), ([0.006711409395973154, 0.1666666666666668, 0.41666666666666663, 0.06779661016949151, 0.04166666666666667], [1, 0, 0]), ([0.3825503355704698, 0.1666666666666668, 0.1666666666666666, 0.38983050847457623, 0.375], [0, 1, 0]), ([0.21476510067114093, 0.25000000000000006, 0.8749999999999998, 0.0847457627118644, 0.0], [1, 0, 0]), ([0.3221476510067114, 0.27777777777777773, 0.7083333333333333, 0.0847457627118644, 0.04166666666666667], [1, 0, 0]), ([0.18791946308724833, 0.25000000000000006, 0.5833333333333333, 0.06779661016949151, 0.04166666666666667], [1, 0, 0]), ([0.7315436241610739, 0.8055555555555556, 0.6666666666666666, 0.8644067796610169, 1.0], [0, 0, 1]), ([0.5436241610738255, 0.3333333333333333, 0.1666666666666666, 0.4576271186440678, 0.375], [0, 1, 0]), ([0.6375838926174496, 0.38888888888888895, 0.41666666666666663, 0.5423728813559322, 0.4583333333333333], [0, 1, 0]), ([0.6577181208053692, 0.22222222222222213, 0.20833333333333331, 0.3389830508474576, 0.4166666666666667], [0, 1, 0]), ([1.0, 0.44444444444444453, 0.41666666666666663, 0.6949152542372881, 0.7083333333333334], [0, 0, 1]), ([0.03355704697986577, 0.30555555555555564, 0.7916666666666665, 0.11864406779661016, 0.12500000000000003], [1, 0, 0]), ([0.15436241610738255, 0.22222222222222213, 0.5416666666666665, 0.11864406779661016, 0.16666666666666669], [1, 0, 0]), ([0.28859060402684567, 0.19444444444444448, 0.6249999999999999, 0.1016949152542373, 0.20833333333333334], [1, 0, 0]), ([0.5167785234899329, 0.6666666666666666, 0.41666666666666663, 0.6779661016949152, 0.6666666666666666], [0, 1, 0]), ([0.174496644295302, 0.19444444444444448, 0.5833333333333333, 0.1016949152542373, 0.12500000000000003], [1, 0, 0]), ([0.9328859060402684, 0.7222222222222222, 0.4583333333333333, 0.7457627118644068, 0.8333333333333334], [0, 0, 1]), ([0.9932885906040269, 0.5277777777777778, 0.5833333333333333, 0.7457627118644068, 0.9166666666666666], [0, 0, 1]), ([0.9463087248322147, 0.7222222222222222, 0.4583333333333333, 0.6949152542372881, 0.9166666666666666], [0, 0, 1]), ([0.7046979865771812, 0.9166666666666665, 0.41666666666666663, 0.9491525423728813, 0.8333333333333334], [0, 0, 1]), ([0.0, 0.22222222222222213, 0.6249999999999999, 0.06779661016949151, 0.04166666666666667], [1, 0, 0]), ([0.5033557046979866, 0.6388888888888887, 0.41666666666666663, 0.576271186440678, 0.5416666666666666], [0, 1, 0]), ([0.5100671140939598, 0.6944444444444443, 0.3333333333333332, 0.6440677966101694, 0.5416666666666666], [0, 1, 0]), ([0.6442953020134228, 0.38888888888888895, 0.3749999999999999, 0.5423728813559322, 0.5], [0, 1, 0]), ([0.610738255033557, 0.4999999999999999, 0.41666666666666663, 0.6101694915254237, 0.5416666666666666], [0, 1, 0]), ([0.28187919463087246, 0.027777777777777922, 0.5, 0.05084745762711865, 0.04166666666666667], [1, 0, 0]), ([0.6308724832214765, 0.361111111111111, 0.2916666666666667, 0.5423728813559322, 0.5], [0, 1, 0]), ([0.5906040268456376, 0.361111111111111, 0.41666666666666663, 0.5254237288135593, 0.5], [0, 1, 0]), ([0.7785234899328859, 0.611111111111111, 0.41666666666666663, 0.7627118644067796, 0.7083333333333334], [0, 0, 1]), ([0.9865771812080537, 0.611111111111111, 0.41666666666666663, 0.711864406779661, 0.7916666666666666], [0, 0, 1]), ([0.8791946308724832, 1.0, 0.7499999999999998, 0.9152542372881356, 0.7916666666666666], [0, 0, 1]), ([0.7516778523489933, 0.6944444444444443, 0.41666666666666663, 0.7627118644067796, 0.8333333333333334], [0, 0, 1]), ([0.10738255033557047, 0.30555555555555564, 0.7916666666666665, 0.05084745762711865, 0.12500000000000003], [1, 0, 0]), ([0.7986577181208053, 0.4722222222222222, 0.0833333333333334, 0.6779661016949152, 0.5833333333333334], [0, 0, 1])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = Layer(\n",
        "    neurons=[Neuron(WeightsInitializer.random_uniform(2)) for _ in range(4)]\n",
        ")\n",
        "\n",
        "hidden_layer_1 = Layer(\n",
        "    neurons=[Neuron(WeightsInitializer.random_uniform(4)) for _ in range(5)]\n",
        ")\n",
        "\n",
        "hidden_layer_2 = Layer(\n",
        "    neurons=[Neuron(WeightsInitializer.random_uniform(5)) for _ in range(4)]\n",
        ")\n",
        "\n",
        "output_layer = Layer(\n",
        "    neurons=[Neuron(WeightsInitializer.random_uniform(4)) for _ in range(3)],\n",
        "    is_output_layer=True\n",
        ")\n",
        "\n",
        "network = Network(\n",
        "    layers=[input_layer, hidden_layer_1, hidden_layer_2, output_layer],\n",
        "    epochs=1000,\n",
        "    learning_rate=0.05\n",
        ")\n",
        "\n",
        "network.train(train)\n",
        "accuracy = network.evaluate(test)\n",
        "print(f\"Test Accuracy: {accuracy:.2%}\")\n",
        "\n",
        "# network.save_weights(\"iris_model.pkl\")\n",
        "# network.load_weights(\"iris_model.pkl\")"
      ],
      "metadata": {
        "id": "xrEKj4tMsYN8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}